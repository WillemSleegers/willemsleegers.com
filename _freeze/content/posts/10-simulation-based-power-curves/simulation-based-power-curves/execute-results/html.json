{
  "hash": "d81ac8b585847f74f66b268b57a100cb",
  "result": {
    "markdown": "---\ntitle: Simulation-based power curves\ndescription-meta: \"In this post I show how to do simulated-based power analyses that produce a power curve: the obtained power for a range of sample sizes.\"\ndate: 2021-11-09\ncategories:\n  - power analysis\n  - simulation\n  - statistics\ncode-fold: show\ncode-tools: true\n---\n\nIn a previous post I covered how to perform simulation-based power analyses. A limitation in that post is that usually the question is not what our power is, but rather which sample size gives us the desired power. With the code from my previous post you can get to the right sample size by changing the sample size parameters and then checking whether this gives you enough power. It's fine, but it's a little bit of a hassle.\n\nA more substantive, and related, limitation is that statistical power isn't about a single threshold number that you're supposed to reach. Power is a curve, after all. The difference between having obtained 79% power or 80% power is only 1% and does not strongly affect the interpretation of your obtained power. The code from my previous post doesn't really illustrate this point, so let's do that here.\n\n## Setup\n\nIf you want to follow along, run the following setup code:\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(effectsize)\nlibrary(knitr)\n\n# Set the default ggplot theme\ntheme_set(theme_minimal())\n\n# Set options\noptions(\n  knitr.kable.NA = \"\",\n  digits = 2\n)\n```\n:::\n\n## The scenario\n\nLet's look at one of the scenarios from the previous post: the two *t*-test scenario. We have one treatment condition and two control conditions. Our goal is to have enough power to find a significant difference between the treatment condition and *both* control conditions. Let's begin with a single simulation, just to see what the data would look like.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Parameters\nM_control1 <- 5\nM_control2 <- M_control1\nM_treatment <- 5.5\nSD_control1 <- 1\nSD_control2 <- SD_control1\nSD_treatment <- 1.5\nN <- 50\n\n# Simulate once\ncontrol1 <- mvrnorm(N, mu = M_control1, Sigma = SD_control1^2, \n  empirical = TRUE)\ncontrol2 <- mvrnorm(N, mu = M_control2, Sigma = SD_control2^2, \n  empirical = TRUE)\ntreatment <- mvrnorm(N, mu = M_treatment, Sigma = SD_treatment^2, \n  empirical = TRUE)\n\n# Prepare data\ncolnames(control1) <- \"DV\"\ncolnames(control2) <- \"DV\"\ncolnames(treatment) <- \"DV\"\n\ncontrol1 <- control1 %>%\n  as_tibble() %>%\n  mutate(condition = \"control 1\")\n\ncontrol2 <- control2 %>%\n  as_tibble() %>%\n  mutate(condition = \"control 2\")\n\ntreatment <- treatment %>%\n  as_tibble() %>%\n  mutate(condition = \"treatment\")\n\ndata <- bind_rows(control1, control2, treatment)\n```\n:::\n\nI've changed the code a little bit compared to my previous post. We still assume the same parameters in both control conditions, but now I use one of the control condition variables to set the value of the variable from the other control condition. This means you only need to set the value once and this reduces mistakes due to typos. In addition, we assume the same sample size in each condition and I also changed the parameter values.\n\nWe inspect the data by visualizing it and by calculating a standardized effect size that quantifies the difference between the treatment condition and each of the two control conditions.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate standardized effect size\neffect_size <- cohens_d(DV ~ condition, pooled_sd = FALSE,\n  data = filter(data, condition != \"control 1\"))\n\n# Visualize the data\nggplot(data, aes(x = condition, y = DV)) + \n  geom_jitter(width = .2, alpha = .25) + \n  stat_summary(fun.data = \"mean_cl_boot\", geom = \"pointrange\") +\n  labs(x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![Three groups visualization](simulation-based-power-curves_files/figure-html/fig-two-t-tests-1.png){#fig-two-t-tests width=672}\n:::\n:::\n\nThe effect size is a Cohen's *d* -0.39 and although the Cohen's *d* is negative (due to the ordering the levels in the condition column), the values in the treatment condition are higher than in the control conditions.\n\nAs a reminder, I think we should analyze this data with two Welch's two sample *t*-tests: one for the difference between the treatment condition and control group 1 and also one between the treatment condition and control group 2. Below is some code to run these tests with the current data frame.\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(DV ~ condition, data = filter(data, condition != \"control 1\"))\nt.test(DV ~ condition, data = filter(data, condition != \"control 2\"))\n```\n:::\n\n## The power analysis\n\nNext we want to calculate the power. However, we don't just want the power for a single sample size. We want to calculate the power for a range of sample sizes. So we begin by defining this range. In the example below, we create a variable called `Ns` that contains a sequence of values ranging from 50 to 250, in steps of 50. We also define `S`, which is the number of iterations in the power analysis. The higher this number, the more accurate the power analysis. Note that I've capitalized it this time. The final simulation parameter is `i`. I've defined this variable to keep track of how often we loop. This will be useful for figuring out where to store the p-values.\n\nWe will store the p-values in a data frame this time. Using the `crossing()` function, we can create a data frame that contains all possible combinations of the sample sizes and the number of simulation iterations. We can also already add some empty columns to store the p-values in.\n\nAfter that, we begin the loop. We want to loop over each sample size and we want to loop `S` times for each sample size, running the analyses in every single loop. This means we have a nested `for` loop. This is not particularly difficult, as we can simply put a `for` loop within a `for` loop. The only trick bit is to make sure that you store the p-values correctly. That's where the `i` variable comes in. We initially gave it a value of 1, so the first p-values will be stored in the first row. At the end of each loop we increment it by 1, making sure that the next p-values will be stored in the next row of our p-values data frame.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set simulation parameters\nNs <- seq(from = 50, to = 250, by = 50)\nS <- 1000\ni <- 1 \n\n# Create a data frame to store the p-values in\np_values <- crossing(\n  n = Ns,\n  s = 1:S,\n  p_value1 = NA,\n  p_value2 = NA\n)\n\n# Loop\nfor (n in Ns) {\n  for (s in 1:S) {\n    # Simulate\n    control1 <- mvrnorm(n, mu = M_control1, Sigma = SD_control1^2)\n    control2 <- mvrnorm(n, mu = M_control2, Sigma = SD_control2^2)\n    treatment <- mvrnorm(n, mu = M_treatment, Sigma = SD_treatment^2)\n    \n    # Run tests\n    test1 <- t.test(control1[, 1], treatment[, 1])\n    test2 <- t.test(control2[, 1], treatment[, 1])\n    \n    # Extract p-values\n    p_values$p_value1[i] <- test1$p.value\n    p_values$p_value2[i] <- test2$p.value\n  \n    # Increment i\n    i <- i + 1\n  }\n}\n```\n:::\n\nThe result is a data frame with two columns containing p-values. To calculate the power, we sum the number of times we find a significant effect in *both* columns and divide it by the number of iterations per sample size (`S`). We need to do this for each sample size. The following code does the trick:\n\n::: {.cell}\n\n```{.r .cell-code}\npower <- p_values %>%\n  mutate(success = if_else(p_value1 < .05 & p_value2 < .05, 1, 0)) %>%\n  group_by(n) %>%\n  summarize(power = sum(success) / S)\n```\n:::\n\n## The power curve\n\nWith the power for each sample size calculated, we can visualize the power curve.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(power, aes(x = n, y = power)) +\n  geom_line(linetype = 2) +\n  geom_point() +\n  geom_hline(yintercept = .80, linetype = 3) +\n  geom_hline(yintercept = .95, linetype = 3) +\n  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +\n  labs(x = \"Sample size (n) per condition\", y = \"Power\")\n```\n\n::: {.cell-output-display}\n![The power curve](simulation-based-power-curves_files/figure-html/fig-two-t-tests-power-curve-1.png){#fig-two-t-tests-power-curve width=672}\n:::\n:::\n\nThat's it. We can see at which point we have enough power (e.g., 80% or 95%). Do note that we calculated the sample size *per condition*. In the current scenario, this means you need to multiply the sample size by three in order to obtain your total sample size.\n\nIf you want a smoother graph, you can adjust the range of sample sizes that we stored in the `Ns` variable. You can, for example, lower the `by` argument in the `seq()` function to get a more fine-grained curve.\n\n*This post was last updated on 2022-04-14.*",
    "supporting": [
      "simulation-based-power-curves_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}