{
  "hash": "c626c1bc0d118fbd00f7ef356ffc1fab",
  "result": {
    "markdown": "---\ntitle: \"Bayesian tutorial: Correlation\"\ndescription: \"The third of a series of tutorial posts on Bayesian analyses. In this post I focus on using `brms` to model a correlation.\"\ndate: 2022-11-24\ncategories:\n  - statistics\n  - tutorial\n  - Bayesian statistics\n  - regression\ncode-fold: true\ncode-tools: true\ntoc: true\ndraft: true\n---\n\n\nIn my previous [blog post](../18-bayesian-tutorial-simple-regression/bayesian-tutorial-simple-regression.qmd), I showed how to use `brms` and `tidybayes` to run a simple regression, i.e., a regression with a single predictor. This analysis required us to set three priors: an intercept prior, a sigma prior, and a slope prior. We can simplify this analysis by turning it into a correlational analysis. This will remove the intercept prior and lets us think about the prior for the slope in as a standardized effect size, i.e., the correlation. \n\nTo run a correlational analysis we'll need to standardize the outcome and predictor variable, so in the code below I run the setup code as usual and also standardize both variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\n\ndata <- read_csv(\"Howell1.csv\") |>\n  filter(age >= 18) |>\n  mutate(\n    height_z  = (height - mean(height)) / sd(height),\n    weight_z  = (weight - mean(weight)) / sd(weight),\n  )\n\ntheme_set(theme_minimal())\n\ncolors <- c(\"#93CFDB\", \"#1E466E\")\n```\n:::\n\n\nThe formula for our model is slightly different compared to the formula of the previous single-predictor model and that's because we can omit the intercept. By standardizing both the outcome and predictor variables, the intercept is guarenteed to be 0. The regression line always passes through the mean of the predictor and outcome variable. The mean of both is 0 because of the standardization and the intercept is the value the outcome takes when the predictor is 0. We could still include a prior for the intercept and set it to 0 (using `constant(0)`) but we can also simply tell `brms` not to estimate it. The formula syntax then becomes: `height_z ~ 0 + weight_z`.\n\nLet's confirm that this means we only need to set two priors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_prior(height_z ~ 0 + weight_z, data = data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                prior class     coef group resp dpar nlpar lb ub       source\n               (flat)     b                                           default\n               (flat)     b weight_z                             (vectorized)\n student_t(3, 0, 2.5) sigma                                 0         default\n```\n:::\n:::\n\n\nIndeed, we're left with a prior for $\\sigma$ and one for `weight_z`, which we can specify either via class `b` or the specific coefficient for `weight_z`. \n\nLet's also write down our model more explicitly, which is the same as the single predictor regression but without the intercept ($\\alpha$).\n$$\\displaylines{heights_i âˆ¼ Normal(\\mu_i, \\sigma) \\\\ \\mu_i = \\beta x_i}$$\n\n## Setting the priors\n\nLet's start with the prior for the slope ($\\beta$). A correlation takes a value that ranges from -1 to 1. If you know absolutely nothing about what kind of correlation to expect, you could set a uniform prior that assign equals probability to every value from -1 to -1. Alternatively, we could use a prior that describes a belief that no correlation is most likely, but with some probability that higher correlations are possible too. This could be done with a normal distribution centered around 0. In the case of this particular model, in which height is regressed onto weight, we can probably expect a sizeable positive correlation. So let's use a skewed normal distribution that puts most of the probability on a positive correlation but is wide enough to allow for a range of correlations, including a negative one. `brms` has the `skew_normal()` function to specify a prior that's a skewed normal distribution. I fiddled around with the numbers a bit and the distribution below is sort of what makes sense to me.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- tibble(r = seq(-1, 1, .01)) %>%\n  mutate(\n    prob = dskew_normal(r, xi = .7, omega = .4, alpha = -3)\n  )\n\nggplot(prior, aes(x = r, y = prob)) + \n  geom_line() +\n  labs(x = \"Slope\", y = \"\")\n```\n\n::: {.cell-output-display}\n![Prior distribution for the correlation](bayesian-tutorial-correlations_files/figure-html/slope-prior-1.png){width=672}\n:::\n:::\n\n\nWhat should the prior for $\\sigma$ be? With the variables standardized, $\\sigma$ is limited to range from 0 to 1. If the predictor explains all the variance of the outcome variable, the residuals will be 0, meaning $\\sigma$ will be 0. If the predictor explains no variance, $\\sigma$ is equal to 1 because it will be similar to the standard deviation of the outcome variable, which is 1 because we've standardized it. Interestingly, this also means that the prior for $\\sigma$ is now dependent on the prior for the slope, because the slope is what determines how much variance is explained in the outcome variable. I don't know exactly how to deal with this dependency, except to fear it and make sure to carefully inspect the output so that we don't have any problems due to incompatible priors. One way to avoid it entirely is to use a uniform prior that assign equal plausibility to each value between 0 and 1, so let's do that.\n\n## Running the model\n\nWith the priors ready, we can run the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- brm(\n  height_z ~ 0 + weight_z,  \n  data = data, \n  family = gaussian,\n  prior = c(\n      prior(uniform(0, 1), class = \"sigma\", ub = 1),\n      prior(\n        skew_normal(.7, .4, -3), \n        class = \"b\", lb = -1, ub = 1\n      )\n    ), \n  sample_prior = TRUE,\n  cores = 4,\n  seed = 4,\n  file = \"models/model.rds\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCompiling Stan program...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n```{.r .cell-code}\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height_z ~ 0 + weight_z \n   Data: data (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nweight_z     0.75      0.03     0.68     0.81 1.00     2816     1902\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.66      0.02     0.61     0.71 1.00     2939     2107\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nThe output shows that the estimate for the slope, i.e., the correlation, is 0.75. This is just one number though. Let's visualize the entire distribution, including the prior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndraws <- model %>%\n  gather_draws(prior_b, b_weight_z) %>%\n  ungroup() %>%\n  mutate(\n    distribution = if_else(\n      str_detect(.variable, \"prior\"), \"prior\", \"posterior\"\n    ),\n    distribution = fct_relevel(distribution, \"prior\")\n  )\n\nggplot(draws, aes(x = .value, fill = distribution)) +\n  geom_histogram(position = \"identity\", alpha = .85) +\n  labs(x = \"Correlation\", y = \"\", fill = \"Distribution\") +\n  scale_fill_manual(values = colors)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](bayesian-tutorial-correlations_files/figure-html/correlation-1.png){width=672}\n:::\n:::\n\n\nIt looks like we can update towards a higher correlation and also be more certain about it because the range of the posterior is much narrower than that of our prior. \n\nWhat about sigma? Sigma is the standard deviation of the residuals, i.e., that what is unexplained by the predictor. We saw that the correlation between the predictor and outcome is 0.75. Squaring this number gives us the amount of variance explained (0.56), so if we subtract this from 1 we're left with the variance that is unexplained (0.44). Squaring this number to bring it back to a standard deviations gives us 0.67, which matches the estimate for sigma that we saw in the output of `brms`.\n\n## Using a regularizing prior\n\nIn the previous section we used a personal and hopefully informed prior, at least to some degree. What would happen if we instead used a [generic weakly informative prior](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)? This is a prior centered at 0 with a standard deviation of 1.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- tibble(r = seq(-1, 1, .01)) %>%\n  mutate(\n    prob = dnorm(r, mean = 0, sd = 1)\n  )\n\nggplot(prior, aes(x = r, y = prob)) + \n  geom_line() +\n  labs(x = \"Slope\", y = \"\")\n```\n\n::: {.cell-output-display}\n![Generic weakly informationve prior for the correlation](bayesian-tutorial-correlations_files/figure-html/weakly-informative-slope-prior-1.png){width=672}\n:::\n:::\n\n\nIt's a very broad prior, ranging from -1 to 1. It is, however, centered at 0 so wouldn't that push the final estimate closer to a null effect? Let's see by running the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_generic_prior <- brm(\n  height_z ~ 0 + weight_z,  \n  data = data, \n  family = gaussian,\n  prior = c(\n      prior(uniform(0, 1), class = \"sigma\", ub = 1),\n      prior(\n        normal(0, 1), \n        class = \"b\", lb = -1, ub = 1\n      )\n    ), \n  sample_prior = TRUE,\n  cores = 4,\n  seed = 4,\n  file = \"models/model_generic_prior_z.rds\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCompiling Stan program...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n```{.r .cell-code}\nmodel_generic_prior\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height_z ~ 0 + weight_z \n   Data: data (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nweight_z     0.76      0.04     0.69     0.82 1.00     2952     2120\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.66      0.03     0.61     0.71 1.00     2780     2000\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nThe previous estimate of the correlation was 0.75 and now it's 0.76. Apparently the prior did not influence the final estimate. This hopefully alleviates some worries about priors always having a strong impact on the final results and it also shows you don't always need to carefully construct a prior. Of course, in certain cases the prior will have a strong influence, for example when the prior is very strong or when there isn't much data.\n\n## Multiple correlations\n\nWhat if you want to test multiple correlations? There are two ways to do this, as far as I know. The first is to simply run separate models, each testing a single correlation. The second is by creating a model that tests multiple correlations at once. The latter is possible but it's more complicated and I don't fully understand it yet. If you want to see how it is done, please see this [blog post](https://solomonkurz.netlify.app/blog/2019-02-16-bayesian-correlations-let-s-talk-options/) by Solomon Kurz.\n\nI'll instead focus on simply running multiple models, but to make it easier I'll show how to use the `update()` function in `brms` so we at least don't have to write as much code. In the code below I standardize `age` and run three models in total, correlating `height` with `weight`, `height` with `age`, and `age` with `weight`. I'll use the same generic prior from the last model and repeat the full code for that model, followed by two updates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- mutate(data, age_z = (age - mean(age)) / sd(age))\n\nr_height_weight <- brm(\n  height_z ~ 0 + weight_z,  \n  data = data, \n  family = gaussian,\n  prior = c(\n      prior(uniform(0, 1), class = \"sigma\", ub = 1),\n      prior(normal(0, 1), class = \"b\", lb = -1, ub = 1)\n    ), \n  cores = 4,\n  seed = 4,\n  file = \"models/r_height_weight.rds\",\n  control = list(adapt_delta = 0.9)\n)\n\nr_height_age <- update(\n  r_height_weight, \n  height_z ~ 0 + age_z, \n  newdata = data,\n  file = \"models/r_height_age.rds\"\n)\nr_weight_age <- update(\n  r_height_weight, \n  weight_z ~ 0 + age_z, \n  newdata = data,\n  file = \"models/r_weight_age.rds\"\n)\n\nr_height_weight\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height_z ~ 0 + weight_z \n   Data: data (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nweight_z     0.75      0.04     0.69     0.82 1.00     2505     2066\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.66      0.03     0.61     0.71 1.00     2347     1795\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nr_height_age\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height_z ~ age_z - 1 \n   Data: data (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nage_z    -0.10      0.05    -0.21    -0.00 1.00     1911     1804\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.97      0.02     0.92     1.00 1.00     1569     1226\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nr_weight_age\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: weight_z ~ age_z - 1 \n   Data: data (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nage_z    -0.17      0.05    -0.28    -0.07 1.00     2123     1952\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.97      0.02     0.91     1.00 1.00     1223      853\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nWhen I first ran the code above I received a warning that there were divergent transitions after warmup for the extra two correlations. That means the posterior may not have been sampled correctly, which is a problem. The solution is to increase the `adapt_delta` value. What that does is simply make the underlying sampler more conservative, which will increase the accuracy of approximating the posterior but might slow down the sampler.\n\nLet's create a nice plot showing the correlations. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrelations <- bind_rows(\n  tibble(\n    pair = \"height - weight\",\n    r = spread_draws(r_height_weight, b_weight_z)[[4]]\n  ),\n  tibble(\n    pair = \"height - age\",\n    r = spread_draws(r_height_age, b_age_z)[[4]]\n  ),\n  tibble(\n    pair = \"weight - age\",\n    r = spread_draws(r_weight_age, b_age_z)[[4]]\n  ),\n)\n\ncorrelations\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12,000 Ã— 2\n   pair                r\n   <chr>           <dbl>\n 1 height - weight 0.775\n 2 height - weight 0.775\n 3 height - weight 0.747\n 4 height - weight 0.769\n 5 height - weight 0.755\n 6 height - weight 0.798\n 7 height - weight 0.815\n 8 height - weight 0.826\n 9 height - weight 0.683\n10 height - weight 0.769\n# â€¦ with 11,990 more rows\n```\n:::\n\n```{.r .cell-code}\nggplot(correlations, aes(x = r, y = pair)) +\n  stat_halfeye()\n```\n\n::: {.cell-output-display}\n![](bayesian-tutorial-correlations_files/figure-html/correlations-1.png){width=672}\n:::\n:::\n\n\n## Summary\n\n\n\n\n",
    "supporting": [
      "bayesian-tutorial-correlations_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}