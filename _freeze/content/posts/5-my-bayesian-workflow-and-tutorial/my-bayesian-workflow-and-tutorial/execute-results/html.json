{
  "hash": "2f9273ad5d361c1fc6d63da14a1b22cd",
  "result": {
    "markdown": "---\ntitle: \"My Bayesian Workflow + Tutorial\"\ndescription: \"Bayesian statistics seems pretty cool, but I don't really know how to apply it yet. In this blog post, I try to setup a Bayesian workflow that teaches both you and me how to do it.\"\ndate: 2020-12-08\ncategories:\n  - statistics\n  - tutorial\n  - Bayesian\n  - regression\ncode-fold: true\ntoc: true\ndraft: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(brms)\nlibrary(tidybayes)\nlibrary(here)\n\n# Load data\ndata <- read_csv(here(\"data\", \"Howell1.csv\"))\n\n# Set seed\nset.seed(4)\n\n# Set options\noptions(\n  knitr.kable.NA = \"-\", \n  digits = 2\n)\n```\n:::\n\nIn this post, I am going to work out a workflow that I think makes sense for analyzing data using Bayesian statistics.\n\nThe data we will use to play with is the same data Richard McElreath uses in Chapter 4 of his amazing book called Statistical Rethinking. It is a dataset containing people's height, weight, age, and sex.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Only select people older than 18\ndata <- filter(data, age >= 18)\n\n# Show the first rows\ndata %>%\n  head() %>%\n  kable(col.names = str_to_title(names(.)))\n```\n\n::: {.cell-output-display}\n| Height| Weight| Age| Male|\n|------:|------:|---:|----:|\n|    152|     48|  63|    1|\n|    140|     36|  63|    0|\n|    137|     32|  65|    0|\n|    157|     53|  41|    1|\n|    145|     41|  51|    0|\n|    164|     63|  35|    1|\n:::\n:::\n\nThe general idea behind Bayesian statistics is that you start with some beliefs about the data and then update those beliefs with the data, resulting in an updated belief.\n\nThis means that when we want to analyze this data, we should actually start with our beliefs. We should therefore not start by looking at the data. That's why I only showed you the first few rows of the dataset here. Instead, we should construct a model that describes the different heights based on our a priori knowledge of people's heights. In other words, we have to describe what we believe the heights to be. This is unlike what you have to do with frequentist statistics, so this part might be a bit tricky.\n\nWe will use the amazing `brms` package to do both analyze our beliefs and the data.\n\n## An intercept-only model\n\nLet's start with a simple intercept-only model to describe the heights. This means that our formula will be: `height ~ 1`.\n\nWe can now use `brms` to figure out which priors we need to set by running the `get_prior()` function.\n\n::: {.cell}\n\n```{.r .cell-code}\nget_prior(height ~ 1, data = data)\n```\n\n::: {.cell-output-stdout}\n```\n                    prior     class coef group resp dpar nlpar bound  source\n student_t(3, 154.3, 8.5) Intercept                                  default\n     student_t(3, 0, 8.5)     sigma                                  default\n```\n:::\n:::\n\nThis shows us that we need to set two priors, one for the Intercept and one for sigma. `brms` determined these priors automatically, but let's take a look at them and see if we can do better.\n\n### The Intercept prior\n\nThe prior for the intercept indicates what we believe the average height to be.\n\n`brms` has set the default Intercept prior as a Student *t* distribution with 3 degrees of freedom, a $\\mu$ of 154.3 and a $\\sigma$ of 8.5. That means `brms` starts off with a 'belief' that the average height is roughly normally distributed, with the most common average height being 154.3, but with quite some uncertainty. In fact, a Student *t* distribution has thick tails, especially compared to a normal distribution. This means that although you think the average height is most likely to be 154.3, you also think quite some other values are possible, even much smaller or much taller heights.\n\nBut this is the default prior. `brms` determines this automatic prior by peeking at the data, which is not what we want to do. Instead, we should create our own.\n\nSo what do I believe the average height to be? As a Dutch person, I might be under the impression that the average height is around 175 centimeters. This is probably too tall for an average, as we're known for being quite tall. So I think the average should be a bit lower than 175, perhaps 170. I am not very sure, though. After all, I am far from an expert on people's heights; I am only using my layman knowledge here. As a result, an average of 165 seems possible to me, too. So let's describe my belief in the form of a distribution in which multiple averages are possible, to varying extents. We could use different types of distributions for this purpose. We could use a Student *t* distribution, but we can also use a normal distribution. We should use a Student *t* distribution with small degrees of freedom if we want to allow for the possibility of being very wrong (remember, it has thicker tails, so it covers a wider range of average heights). We're not super uncertain about people's heights, though, so let's use a normal distribution.\n\nDefining a normal distribution requires that we set the $\\mu$ and the $\\sigma$. The $\\mu$ we already covered (i.e., 170), so that leaves $\\sigma$. Let's set this to 10 and see what happens by visualizing this prior. Below I plot both the default `brms` prior and our own.\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(height_mean = seq(from = 100, to = 250, by = .1)) %>%\n  mutate(\n      ours = dnorm(height_mean, mean = 170, sd = 10),\n      default = dstudent_t(height_mean, df = 30, mu = 154.3, sigma = 8.5),\n    ) %>%\n  pivot_longer(cols = -height_mean, names_to = \"prior\") %>%\n  ggplot(aes(x = height_mean, y = value, color = prior)) +\n    geom_line(size = 1) +\n    labs(x = \"Average height\", y = \"\", color = \"Prior\") +\n    scale_x_continuous(breaks = seq(100, 250, 10))\n```\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/height-mu-prior-1.png){width=672}\n:::\n:::\n\nSo, it seems that compared to `brms`, our prior indicates that we believe the average height to be higher. In terms of the standard deviation, we both seem to be about equally uncertain about this average. To be fair, I think this prior of ours is not very plausible. Apparently we assign quite a chunk of plausibility to an average of 180 cm, or even 190 cm, which is unlikely. An average of 160 cm is more plausible to me than an average of 180, so I should probably lower the mu, or use more of a skewed distribution. Regardless, we can keep it like this. We'll see later that our data easily overshadows our prior.\n\n## The sigma prior\n\nWhat about the standard deviation? I find setting the standard deviation of distribution of heights (not the mean of the heights) quite difficult. There are parts that are easy, such as the fact that the standard deviation has to be 0 or larger (it can't be negative), but exactly how large it should be, I don't know.\n\nI do know it is unlikely to be close to 0, and unlikely to be very large. This means the peak should be somewhere above 0, with a tail to allow higher values but not too high. We can use a normal distribution for this with a mean above 0 and a particular standard deviation, and ignore everything that's smaller than 0.\n\nThere is a downside of using a normal distribution, though. Normal distributions have long tails, but there is actually very little density in those tails. If we are quite uncertain about our belief about sigma, we should allow for this. One way to do this is by using a cauchy distribution. Cauchy distributions are like normal distributions, but with thicker tails. In fact, the cauchy distribution is a special case of the Student *t* distribution; they are equivalent if the degree of freedom is 1.\n\nThe cauchy distribution also requires two parameters: $\\mu$ and $\\sigma$. I set $\\mu$ to 5 and $\\sigma$ to 5 as well. Below I plot this prior and `brms`'s default prior.\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(height_sigma = seq(from = 0, to = 50, by = .1)) %>%\n  mutate(\n      default = dstudent_t(height_sigma, df = 3, mu = 0, sigma = 8.5) * 2,\n      ours = dstudent_t(height_sigma, df = 1, mu = 5, sigma = 1) * 2,\n    ) %>%\n  pivot_longer(cols = -height_sigma, names_to = \"prior\") %>%\n  ggplot(aes(x = height_sigma, y = value, color = prior)) +\n    geom_line(size = 1) +\n    labs(x = \"Standard deviation of heights\", y = \"\", color = \"Prior\")\n```\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/height_sigma_prior-1.png){width=672}\n:::\n:::\n\nAs you can see, both distributions have long tails, allowing for the possibility of high standard deviations. There are some notable differences between the two priors. Our prior puts more weight on a standard deviation larger than 0, while the default prior believes a standard deviation of 0 is more likely. However, both priors are quite weak. We'll see that the data easily overshadows these priors.\n\nBefore we run the analysis, we can also check the results of our priors on the distribution of heights. This is called a prior predictive simulation.\n\n### Checking the priors\n\nBefore we run our model, we should check what the effect is of all our priors combined. By setting the prior we can simulate what we believe the data to be. This is one way to see whether our priors actually make sense. This is called prior predictive checking.\n\nWe can use `brms` to do this by running the `brm()` function. However, instead of running the actual model, we tell it to only sample from the prior.\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_height_prior <- brm(\n    height ~ 1,  \n    data = data, \n    family = gaussian,\n    prior = c(\n        prior(normal(170, 10), class = \"Intercept\"),\n        prior(cauchy(5, 5), class = \"sigma\")\n      ), \n    cores = 4,\n    seed = 4, \n    sample_prior = \"only\",\n    file = \"models/model_height_prior.rds\"\n  )\n```\n:::\n\nWe then use the `tidybayes` package to draw samples from the prior and plot these draws.\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_height_prior %>%\n  predicted_draws(tibble(.rows = 1), prediction = \"predicted_height\") %>%\n  ggplot(aes(x = predicted_height)) +\n    geom_histogram(binwidth = 1) +\n    coord_cartesian(xlim = c(100, 250)) +\n    labs(x = \"Height\", y = \"\")\n```\n\n::: {.cell-output-stderr}\n```\nWarning: \nIn predicted_draws(): The `prediction` argument is a deprecated alias for `value`.\nUse the `value` argument instead.\nSee help(\"tidybayes-deprecated\").\n```\n:::\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/prior_predictive-1.png){width=672}\n:::\n:::\n\nSo, our priors result in a normal distribution of heights ranging from about 125 cm to 225 cm. This looks pretty reasonable to me, so let's run the model for real now.\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_height <- brm(data = data, \n    family = gaussian,\n    height ~ 1,\n    prior = c(\n        prior(normal(170, 10), class = \"Intercept\"),\n        prior(cauchy(5, 1), class = \"sigma\")\n      ),\n    cores = 4,\n    seed = 4,\n    sample_prior = TRUE,\n    file = \"models/model_height.rds\",\n    file_refit = \"on_change\"\n  )\n```\n:::\n\nBefore we check the results, let's first check whether the chains look good.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(model_height)\n```\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/prior_posterior-1.png){width=672}\n:::\n:::\n\nIt seems like they do. This also shows us the posterior distributions of the two parameters. We can also directly compare them to our priors.\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- model_height %>%\n  posterior_samples() %>%\n  select(-lp__) %>%\n  pivot_longer(cols = everything()) %>%\n  mutate(\n    parameter = if_else(str_detect(name, \"sigma\"), \"sigma\", \"intercept\"),\n    distribution = if_else(str_detect(name, \"prior\"), \"prior\", \"posterior\"),\n    distribution = fct_relevel(distribution, \"prior\")\n  ) %>%\n  select(-name)\n```\n\n::: {.cell-output-stderr}\n```\nWarning: Method 'posterior_samples' is deprecated. Please see ?as_draws for\nrecommended alternatives.\n```\n:::\n\n```{.r .cell-code}\nresults_intercept <- filter(results, parameter == \"intercept\")\nresults_sigma <- filter(results, parameter == \"sigma\")\n\nggplot(results_intercept, aes(x = value, fill = distribution)) +\n  geom_histogram(binwidth = 0.5, position = \"identity\") +\n  coord_cartesian(xlim = c(145, 195)) +\n  labs(x = \"Average height\", y = \"\", fill = \"Distribution\")\n```\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/posterior-1.png){width=672}\n:::\n:::\n\nHere we see that the posterior distribution of average heights is now much more narrow and centered around 156 cm.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(results_sigma, aes(x = value, fill = distribution)) +\n  geom_histogram(binwidth = 0.25, position = \"identity\") + \n  coord_cartesian(xlim = c(0, 25)) +\n  labs(x = \"Height standard deviation\", y = \"\", fill = \"Distribution\")\n```\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\nSimilarly, we see that the posterior for sigma is also much more narrow and around 7.75.\n\nWe can call up the estimates and the 95% confidence intervals by printing the model object.\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_height\n```\n\n::: {.cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height ~ 1 \n   Data: data (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   154.63      0.41   153.83   155.40 1.01     3354     2418\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     7.72      0.29     7.18     8.32 1.00     3632     2741\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n## Adding a predictor\n\nLet's repeat the same steps but this time we add a predictor to the model. We'll add weight as a predictor to see its relationship with height.\n\nThe formula becomes: `height ~ 1 + weight`.\n\nSo let's see which priors we need to set for this model.\n\n::: {.cell}\n\n```{.r .cell-code}\nget_prior(height ~ 1 + weight, data = data)\n```\n\n::: {.cell-output-stdout}\n```\n                    prior     class   coef group resp dpar nlpar bound\n                   (flat)         b                                   \n                   (flat)         b weight                            \n student_t(3, 154.3, 8.5) Intercept                                   \n     student_t(3, 0, 8.5)     sigma                                   \n       source\n      default\n (vectorized)\n      default\n      default\n```\n:::\n:::\n\nThis time the output is a bit more confusing. We seem to have two additional priors: a default b prior and a vectorized b prior for the weight coefficient. The reason there are now two additional priors is that there are two different ways to specify a prior here. We can either set a specific prior for the weight coefficient, or set a prior on all the b-class priors. In this specific case, with only one additional predictor, it means we can use either technique and we only need to set one of them.\n\nWhat should our prior for weight be? In other words, for every increase of 1 in weight, how much do we think this relates to an increase (or decrease) in height? This is likely to be a positive relationship (taller people are more likely to be heavier as well), but we can also refrain from indicating the direction. This means we can specify a distribution of possible effects, centered around 0. The only decision we're left with is setting the standard deviation. Let's try a value of 10 and see what this means.\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_height_weight_prior <- brm(\n    height ~ 1 + weight,  \n    data = data, \n    family = gaussian,\n    prior = c(\n        prior(normal(170, 10), class = \"Intercept\"),\n        prior(cauchy(5, 1), class = \"sigma\"),\n        prior(normal(0, 10), coef = \"weight\")\n      ),\n    cores = 4,\n    seed = 4, \n    sample_prior = \"only\",\n    file = \"models/model_height_weight_prior.rds\"\n  )\n```\n:::\n\nWe can do our prior predictive checking in two different ways now. We can check only the effect of our prior on weight, or also include the prior on sigma.\n\nIn the former case, we use `fitted_draws()` to obtain draws from our posterior, like so:\n\n::: {.cell}\n\n```{.r .cell-code}\ndraws <- fitted_draws(\n    model_height_weight_prior, \n    tibble(weight = seq(30, 100, 1)), \n    value = \"fitted_height\", n = 100\n  ) \n```\n\n::: {.cell-output-stderr}\n```\nWarning: `fitted_draws` and `add_fitted_draws` are deprecated as their names were confusing.\nUse [add_]epred_draws() to get the expectation of the posterior predictive.\nUse [add_]linpred_draws() to get the distribution of the linear predictor.\nFor example, you used [add_]fitted_draws(..., scale = \"response\"), which\nmeans you most likely want [add_]epred_draws(...).\n```\n:::\n\n```{.r .cell-code}\nggplot(draws, aes(x = weight, y = fitted_height, group = .draw)) +\n  geom_line(alpha = .5) \n```\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples <-model_height_weight_prior %>%\n  posterior_samples()\n```\n\n::: {.cell-output-stderr}\n```\nWarning: Method 'posterior_samples' is deprecated. Please see ?as_draws for\nrecommended alternatives.\n```\n:::\n\n```{.r .cell-code}\nggplot(samples, aes(x = b_weight)) +\n  geom_histogram()\n```\n\n::: {.cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\nIn the latter case we use `predicted_draws()`, like so:\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_height_weight_prior %>%\n  predicted_draws(tibble(weight = seq(30, 100, 1)), prediction = \"predicted_height\", n = 100) %>%\n  ggplot(aes(x = weight, y = predicted_height, group = .draw)) +\n    geom_line(alpha = .5)\n```\n\n::: {.cell-output-stderr}\n```\nWarning: \nIn predicted_draws(): The `prediction` argument is a deprecated alias for `value`.\nUse the `value` argument instead.\nSee help(\"tidybayes-deprecated\").\n```\n:::\n\n::: {.cell-output-stderr}\n```\nWarning: \nIn predicted_draws(): The `n` argument is a deprecated alias for `ndraws`.\nUse the `ndraws` argument instead.\nSee help(\"tidybayes-deprecated\").\n```\n:::\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\nIn both cases, we see that we get quite some implausible values. So let's take a prior that produces fewer crazy observations, such as a prior of `normal(0, 1)`.\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_height_weight_prior2 <- brm(\n    height ~ 1 + weight,  \n    data = data, \n    family = gaussian,\n    prior = c(\n        prior(normal(170, 10), class = \"Intercept\"),\n        prior(cauchy(5, 1), class = \"sigma\"),\n        prior(normal(0, 1), coef = \"weight\")\n      ),\n    cores = 4,\n    seed = 4, \n    sample_prior = \"only\",\n    file = \"models/model_height_weight_prior2.rds\"\n  )\n\nmodel_height_weight_prior2 %>%\n  fitted_draws(tibble(weight = seq(30, 100, 1)), value = \"fitted_height\", n = 100) %>%\n  ggplot(aes(x = weight, y = fitted_height, color = .draw, group = .draw)) +\n    geom_line(alpha = .5)\n```\n\n::: {.cell-output-stderr}\n```\nWarning: `fitted_draws` and `add_fitted_draws` are deprecated as their names were confusing.\nUse [add_]epred_draws() to get the expectation of the posterior predictive.\nUse [add_]linpred_draws() to get the distribution of the linear predictor.\nFor example, you used [add_]fitted_draws(..., scale = \"response\"), which\nmeans you most likely want [add_]epred_draws(...).\n```\n:::\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/height_weight_prior2-1.png){width=672}\n:::\n:::\n\nThat looks much better. It could still be refined because it produces several highly implausible results, but let's stick with this for now and run the model.\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_height_weight <- brm(\n    height ~ 1 + weight,  \n    data = data, \n    family = gaussian,\n    prior = c(\n        prior(normal(170, 10), class = \"Intercept\"),\n        prior(cauchy(5, 1), class = \"sigma\"),\n        prior(normal(0, 1), coef = \"weight\")\n      ),\n    cores = 4,\n    seed = 4, \n    sample_prior = TRUE,\n    file = \"models/model_height_weight.rds\"\n  )\n```\n:::\n\nLet's check the chains.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(model_height_weight)\n```\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\nAnd let's compare the prior and posterior distribution of our weight predictor.\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- model_height_weight %>%\n  posterior_samples() %>%\n  select(prior_b_weight, b_weight) %>%\n  pivot_longer(cols = everything()) %>%\n  mutate(\n    distribution = if_else(str_detect(name, \"prior\"), \"prior\", \"posterior\")\n  ) %>%\n  select(-name)\n```\n\n::: {.cell-output-stderr}\n```\nWarning: Method 'posterior_samples' is deprecated. Please see ?as_draws for\nrecommended alternatives.\n```\n:::\n\n```{.r .cell-code}\nggplot(results, aes(x = value, fill = distribution)) +\n  geom_histogram(binwidth = 0.1) +\n  coord_cartesian(xlim = c(-3, 3)) +\n  labs(x = \"Average height\", y = \"\", fill = \"Distribution\")\n```\n\n::: {.cell-output-display}\n![](my-bayesian-workflow-and-tutorial_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\nAgain our prior was quite broad and our posterior is much more narrow. In fact, the estimates are:\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_height_weight\n```\n\n::: {.cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height ~ 1 + weight \n   Data: data (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   113.99      1.95   110.21   117.81 1.00     3960     3085\nweight        0.90      0.04     0.82     0.99 1.00     3961     3189\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     5.09      0.19     4.74     5.48 1.00     4790     2766\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\nWeight is positively related with height (0.90), with a 95% CI ranging from 0.82 to 0.99.",
    "supporting": [
      "my-bayesian-workflow-and-tutorial_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}