---
title: Understanding regression (part 2)
description: "summary of part 2 of understanding regression"
date: 2020-08-01
categories:
  - statistics
  - tutorial
code-fold: true
toc: true
draft: true
---

```{r}
#| label: setup
#| message: false

# Load packages
library(tidyverse)
library(viridis)
library(here)

# Load a custom function to calculate the mode
mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Read in Pokémon data
pokemon <- read_csv(here("data", "pokemon.csv"))

# Create a subset with only the first 25 Pokémon
pokemon25 <- filter(pokemon, pokedex <= 25)
pokemon25_50 <- filter(pokemon, pokedex > 25 & pokedex <= 50)

# Create a vector with only the weights
weights <- pull(pokemon, weight)

# Set seed
set.seed(42)

# Set options
options(
  knitr.kable.NA = "-", 
  digits = 2
)

theme_set(theme_minimal())
```

In Part 1 of 'Understanding Regression' we figured out where the estimate of an intercept-only regression model came from. It turned out to be the mean of the data. However, this was only the case if we defined our model's error as the sum of squared residuals. If we don't square the residuals, the best fitting value turned out to be the median of the data.

We also briefly discussed why one could favor squaring the residuals over not squaring them. By squaring the residuals we're punishing models that make larger mistakes. A residual of size 4 gets amplified to being an error of size 16, a residual of size 2 gets doubled to an error of 2 and a residual of 1 is an error of 1. This may simply be a property we like. We may prefer models that make many small errors over models that make large errors. If we do, we could square the residuals and use the mean as our best fitting model. But we can also approach this issue from the other way around. We can think about whether we prefer means over medians. It could be that the mean has certain properties different from that of the median and that may also be better. Part 2 of Understanding Regression is about whether this is the case.

## Population vs. Sample

Remember that our Pokémon weight model was based on the weights of the first 25 Pokémon. This is only a small sample of all Pokémon out there (our data has a total of 893). In the sample we observed, the average weight is `r mean(pull(pokemon25, weight))`. But what if we had instead focused on the next 25 Pokémon, from Raichu to Diglet? The average weight of these Pokémon is `r mean(pull(pokemon25_50, weight))`. That's a difference of `r mean(pull(pokemon25, weight)) - mean(pull(pokemon25_50, weight))`.

Let's actually take a look at the weights of all 893 Pokemon.

```{r}
#| label: fig-pokemon-weights
#| fig-cap: Weights of 893 Pokémon
ggplot(pokemon, aes(x = weight)) +
  geom_histogram(color = "black", alpha = .75, binwidth = 25)
```

This figure shows the weights of *all* the Pokemon that are out there, and thus forms the population of Pokemon weights. Previously we took a *sample* from this population by only looking at 25 Pokemon of this population.

Now imagine that we are not the only ones creating a Pokémon weight model. Instead, we are one of many who are doing so, and we all exchange our model information. We can tell others about our observation that `r paste("weight =", mean(pull(pokemon25, weight)))`. In turn, others will give us their sample means. And let's further imagine that we also encounter people who used the median instead. Below I show some code to create these samples.

```{r}
#| label: samples
samples <- crossing(
    estimator = c("mean", "median"),
    n = c(10, 25, 100),
    i = 1:10000
  ) %>%
  rowwise() %>%
  mutate(
    estimate = if_else(
      condition = estimator == "mean", 
      true = mean(sample(weights, n), na.rm = TRUE),
      false = median(sample(weights, n), na.rm = TRUE)
    )
  )
```

Let's begin by simply looking at the distribution of mean values. The following graph contains 10,000 means, each based on 25 different Pokémon.

```{r}
#| label: fig-pokemon25-mean-weights
#| fig-cap: Distribution of 10,000 means based on 25 Pokémon each
means25 <- filter(samples, estimator == "mean" & n == 25)

ggplot(means25, aes(x = estimate)) +
  geom_density(alpha = .5, fill = "black") +
  geom_vline(xintercept = mean(weights), linetype = "dashed") +
  annotate("text", x = 79, y = 0.0195, label = "population mean") +
  labs(x = "Sample mean", y = "Count")
```

This distribution of means is also called a sampling distribution of means. In our case, we see that

```{r}
estimators25 <- filter(samples, n == 25)

ggplot(estimators25, aes(x = estimate, fill = estimator)) +
  geom_density(alpha = .75, adjust = 2) +
  geom_vline(xintercept = mean(weights), linetype = "solid") +
  geom_vline(xintercept = median(weights), linetype = "dashed") +
  annotate(
    geom = "text", 
    x = mean(weights), 
    y = 0.0465, 
    label = "population mean"
  ) +
  annotate(
    geom = "text", 
    x = median(weights), 
    y = 0.049, 
    label = "population median",
  ) +
  labs(x = "Sample mean", y = "Count") +
  scale_fill_viridis(option = "mako", discrete = TRUE, begin = .25, end = .75) +
  coord_cartesian(ylim = c(0, 0.0425), clip = "off") +
  theme(
    plot.margin = unit(c(2, 1, 1, 1), "lines")
  )
```

## Mean vs. Median

### Normal distribution

```{r}
mean <- 0
sd <- 1
population <- tibble(population = rnorm(10000, mean = mean, sd = sd))

df <- crossing(
    n = c(5, 10, 25, 50, 100, 250),
    i = 1:10000
  ) %>%
  rowwise() %>%
  mutate(
    median = median(rnorm(n = n, mean = mean, sd = sd)),
    mean = mean(rnorm(n = n, mean = mean, sd = sd))
  ) %>%
  pivot_longer(cols = c(median, mean), names_to = "statistic")

ggplot(df, aes(x = value)) +
  #geom_density(mapping = aes(x = population), data = population, alpha = .4) +
  geom_density(mapping = aes(fill = statistic), alpha = .5) +
  facet_wrap(~n, scales = "free_y") +
  scale_fill_viridis(option = "mako", discrete = TRUE, begin = .25, end = .75) +
  theme_minimal()
```

### T-distribution

```{r}
df <- 30
population <- tibble(population = rt(10000, df = df, ncp = 1))

ggplot(population, aes(x = population)) + geom_density()

df <- crossing(
    n = c(5, 10, 25, 50, 100, 250),
    i = 1:10000
  ) %>%
  rowwise() %>%
  mutate(
    median = median(rt(n = n, df = df)),
    mean = mean(rt(n = n, df = df))
  ) %>%
  pivot_longer(cols = c(median, mean), names_to = "statistic")

ggplot(df, aes(x = value)) +
  #geom_density(mapping = aes(x = population), data = population, alpha = .4) +
  geom_density(mapping = aes(fill = statistic), alpha = .5) +
  facet_wrap(~n, scales = "free") +
  scale_fill_viridis(option = "mako", discrete = TRUE, begin = .25, end = .75) +
  theme_minimal()
```

```{r}
library(sn)
population <- rsn(1000, 5, 2, 5)

df <- crossing(
    n = c(5, 10, 25, 50, 100, 250),
    i = 1:1000
  ) %>%
  rowwise() %>%
  mutate(
    median = median(rnorm(n = n, mean = 0, sd = 1)),
    mean = mean(rnorm(n = n, mean = 0, sd = 1))
  ) %>%
  pivot_longer(cols = c(median, mean), names_to = "statistic")

ggplot(df, aes(x = value, fill = statistic)) +
  geom_histogram(binwidth = .05, alpha = .9) +
  facet_wrap(~n, scales = "free") +
  scale_fill_viridis(option = "mako", discrete = TRUE, begin = .25, end = .75) +
  theme_minimal()
```
