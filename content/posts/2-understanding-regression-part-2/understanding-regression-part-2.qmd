---
title: Understanding regression (part 2)
description: "summary of part 2 of understanding regression"
date: 2020-08-01
categories:
  - statistics
  - tutorial
code-fold: true
toc: true
draft: true
---

```{r}
#| label: setup
#| message: false

# Load packages
library(tidyverse)
library(viridis)
library(ggrepel)
library(here)

# Load a custom function to calculate the mode
mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Read in Pokémon data
pokemon <- read_csv(here("data", "pokemon.csv"))

# Create a subset with only the first 25 Pokémon
pokemon25 <- filter(pokemon, pokedex <= 25)
pokemon25_50 <- filter(pokemon, pokedex > 25 & pokedex <= 50)

# Create a vector with only the weights
weights <- pull(pokemon, weight)

# Set seed
set.seed(42)

# Set options
options(
  knitr.kable.NA = "-", 
  digits = 2
)

theme_set(theme_minimal())
```

In Part 1 of 'Understanding Regression' we figured out where the estimate of an intercept-only regression model came from. It turned out to be the mean of the data. However, this was only the case if we defined our model's error as the sum of squared residuals. If we don't square the residuals, the best fitting value is the median of the data. This raises several questions: Why square the residuals? Why choose the mean over the median?

We briefly touched on one answer to that question. By squaring the residuals we're punishing models that make larger mistakes. A residual of size 4 gets amplified to being an error of size 16, a residual of size 2 gets doubled to an error of 2 and a residual of 1 is an error of 1. This may simply be a property we like. We may prefer models that make many small errors over models that make large errors. This is a bit of a value judgement though, so is there another reason to favor means over medians?

The answer is probably, but for us to understand that we should first talk about the population and samples.

## Population vs. Sample

Remember that our Pokémon weight model was based on the weights of the first 25 Pokémon. This is only a small sample of all Pokémon out there (our total is 893). In the sample we observed, the average weight is `r mean(pull(pokemon25, weight))`. But what if we had instead focused on the next 25 Pokémon, from Raichu to Diglet? The average weight of these Pokémon is `r mean(pull(pokemon25_50, weight))`. That's a difference of `r mean(pull(pokemon25, weight)) - mean(pull(pokemon25_50, weight))`.

Let's actually take a look at the weights of all 893 Pokemon.

```{r}
#| label: fig-pokemon-weights
#| fig-cap: Weights of 893 Pokémon
ggplot(pokemon, aes(x = weight)) +
  geom_histogram(color = "black", alpha = .75, binwidth = 25)
```

This figure shows the weights of *all* the Pokemon that are out there, and thus forms the population of Pokemon weights. Previously we took a *sample* from this population by only looking at 25 Pokemon of this population.

Now imagine that we are not the only ones creating a Pokémon weight model. Instead, we are one of many who are doing so, and we all exchange our model information. We can tell others about our observation that `r paste("weight =", mean(pull(pokemon25, weight)))`. In turn, others will give us their sample means. And let's further imagine that we also encounter people who used the median instead. Below I show some code to create these samples.

```{r}
#| label: samples
samples <- crossing(
    estimator = c("mean", "median"),
    n = c(10, 25, 100),
    i = 1:10000
  ) %>%
  rowwise() %>%
  mutate(
    estimate = if_else(
      condition = estimator == "mean", 
      true = mean(sample(weights, n), na.rm = TRUE),
      false = median(sample(weights, n), na.rm = TRUE)
    )
  )
```

Let's begin by simply looking at the distribution of mean values. The following graph contains 10,000 means obtained from 25 different Pokémon.

```{r}
#| label: fig-pokemon25-mean-weights
#| fig-cap: Distribution of 10,000 means based on 25 Pokémon each
means25 <- filter(samples, estimator == "mean" & n == 25)

ggplot(means25, aes(x = estimate)) +
  geom_density(alpha = .5, fill = "black") +
  geom_vline(xintercept = mean(weights), linetype = "dashed") +
  annotate("text", x = 79, y = 0.0195, label = "population mean") +
  labs(x = "Sample mean", y = "Count")
```

This is a sampling distribution of mean estimates.

```{r}
estimators25 <- filter(samples, n == 25)

ggplot(estimators25, aes(x = estimate, fill = estimator)) +
  geom_density(alpha = .75, adjust = 2) +
  geom_vline(xintercept = mean(weights), linetype = "solid") +
  geom_vline(xintercept = median(weights), linetype = "dashed") +
  annotate(
    geom = "text", 
    x = mean(weights), 
    y = 0.046, 
    label = "population mean"
  ) +
  annotate(
    geom = "text", 
    x = median(weights), 
    y = 0.048, 
    label = "population median",
  ) +
  labs(x = "Sample mean", y = "Count") +
  scale_fill_viridis(option = "mako", discrete = TRUE, begin = .25, end = .75) +
  coord_cartesian(ylim = c(0, 0.0425), clip = "off") +
  theme(
    plot.margin = unit(c(3, 1, 1, 1), "lines")
  )
```
