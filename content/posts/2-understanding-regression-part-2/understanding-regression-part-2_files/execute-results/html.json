{
  "hash": "6c107727a9fcea20233456adbf35f2ea",
  "result": {
    "markdown": "---\ntitle: Understanding regression (part 2)\ndescription: \"summary of part 2 of understanding regression\"\ndate: 2020-08-01\ncategories:\n  - statistics\n  - tutorial\ncode-fold: true\ntoc: true\ndraft: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(viridis)\n\n# Read in Pokémon data\npokemon <- read_csv(\"pokemon.csv\")\n\n# Create a subset with only the first 25 Pokémon\npokemon25 <- filter(pokemon, pokedex <= 25)\npokemon25_50 <- filter(pokemon, pokedex > 25 & pokedex <= 50)\n\n# Create a vector with only the weights\nweights <- pull(pokemon, weight)\n\n# Set seed\nset.seed(42)\n\n# Set options\noptions(\n  knitr.kable.NA = \"-\",\n  digits = 2\n)\n\ntheme_set(theme_minimal())\n```\n:::\n\n\nIn [Part](../1-understanding-regression-part-1/understanding-regression-part-1.qmd) 1 of 'Understanding Regression' we figured out where the estimate of an intercept-only regression model came from. It turned out to be the mean of the data. However, this was only the case if we defined our model's error as the sum of squared residuals. If we don't square the residuals, the best fitting value turned out to be the median of the data.\n\nWe also briefly discussed why one could favor squaring the residuals over not squaring them. By squaring the residuals we're punishing models that make larger mistakes. A residual of size 4 gets amplified to being an error of size 16, a residual of size 2 gets doubled to an error of 4 and a residual of 1 is an error of 1. This may simply be a property we like. We may prefer models that make many small errors over models that make large errors. If we do, we could square the residuals and use the mean as our best fitting model. But we can also approach this issue from the other way around. We can think about whether we prefer means over medians. It could be that the mean has certain properties different from that of the median and that may also be better. Part 2 of Understanding Regression is about whether this is the case.\n\n## Bias, efficiency, and consistency\n\nTo determine whether we should prefer the mean over the median, or vice versa, we need to figure out which properties of the estimator we care about. The one's I'm familiar with are unbiasedness, consistency, and effiency. Unbiasedness refers to whether the estimator will correctly estimate the population value. Efficiency refers to how precise the estimator is. The estimator is sampled at a certain sample size and may be more or less precise in estimating the population value. Finally, consistency refers to whether the estimator will become more precise as the sample size increases.\n\nLet's visualize each property by repeatedly calculating the mean of a sample at three different sample sizes. Below I calculate the mean of 10, 25, and 100 samples from a normal distribution with a mean of 0 and a standard deviation of 1. I then plot the distribution of mean values at each sample size (based on 10,000 samples). To help assess the distribution, I also show the 2.5%, 50%, and 97.5% percentile so we can see how variable the mean estimator is and whether it approximates the true parameter (the value 0).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples_mean <- crossing(\n  n = c(10, 25, 100),\n  i = 1:10000\n) %>%\n  rowwise() %>%\n  mutate(value = mean(rnorm(n = n, mean = 0, sd = 1)))\n\nsamples_mean_summary <- samples_mean %>%\n  group_by(n) %>%\n  summarize(\n    low = quantile(value, probs = .025),\n    mid = quantile(value, probs = .5),\n    high = quantile(value, probs = .975),\n    max = max(density(value)$y)\n  )\n\nggplot(samples_mean, aes(x = value)) +\n  geom_density(fill = \"steelblue\", alpha = .85) +\n  facet_grid(~n, labeller = labeller(n = function(x) paste(\"n =\", x))) +\n  geom_text(\n    aes(\n      x = 0,\n      y = max + 0.7,\n      label = paste0(\n        round(mid, 2), \"\\n[\", round(low, 2), \", \", round(high, 2), \"]\"\n      )\n    ),\n    data = samples_mean_summary,\n    color = \"gray20\", size = 3\n  ) +\n  geom_errorbar(\n    aes(xmin = low, xmax = high, y = max + 0.25, x = 0),\n    data = samples_mean_summary, width = .2, color = \"gray20\"\n  ) +\n  labs(x = \"Estimator value\", y = \"\") +\n  scale_y_continuous(labels = NULL)\n```\n\n::: {.cell-output-display}\n![Unbiasedness, efficiency, and consistency of the mean](understanding-regression-part-2_files/figure-html/properties-mean-1.png){width=672}\n:::\n:::\n\n\nThe mean seems to be unbiased because it correctly estimates the value 0 to be the most likely parameter value. The 50% percentile of each distribution is 0. We also see that as the sample size increases, the distribution of means becomes narrower. In other words, the estimate becomes more precise. We can't really judge the efficiency here because we don't have a benchmark to say whether the efficiency is good or bad. We can, however, compare it to using the median.\n\nBelow we repeat the code from before but now we also calculate the median of each sample so that we can compare the distribution of means to the distribution of medians.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples <- crossing(\n  n = c(10, 25, 100),\n  i = 1:10000\n) %>%\n  rowwise() %>%\n  mutate(\n    mean = mean(rnorm(n = n, mean = 0, sd = 1)),\n    median = median(rnorm(n = n, mean = 0, sd = 1))\n  ) %>%\n  pivot_longer(cols = c(mean, median), names_to = \"statistic\")\n\nsamples_summary <- samples %>%\n  group_by(statistic, n) %>%\n  summarize(\n    low = quantile(value, probs = .025),\n    mid = quantile(value, probs = .5),\n    high = quantile(value, probs = .975),\n    max = max(density(value)$y)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'statistic'. You can override using the\n`.groups` argument.\n```\n:::\n\n```{.r .cell-code}\nggplot(samples, aes(x = value)) +\n  geom_density(fill = \"steelblue\", alpha = .85) +\n  facet_grid(\n    statistic ~ n,\n    labeller = labeller(n = function(x) paste(\"n =\", x))\n  ) +\n  geom_text(\n    aes(\n      x = 0,\n      y = max + 0.75,\n      label = paste0(\n        round(mid, 2), \"\\n[\", round(low, 2), \", \", round(high, 2), \"]\"\n      )\n    ),\n    data = samples_summary,\n    color = \"gray20\"\n  ) +\n  geom_errorbar(\n    aes(xmin = low, xmax = high, y = max + 0.25, x = 0),\n    data = samples_summary, width = .2, color = \"gray20\"\n  ) +\n  labs(x = \"Estimator value\", y = \"\") +\n  scale_y_continuous(labels = NULL)\n```\n\n::: {.cell-output-display}\n![](understanding-regression-part-2_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nIt seems that both the mean and the median are unbiased--both produce distributions centered around 0. They are also both consistent, as their precision decreases as the sample size increases. However, their precision seems to differ. The width of the percentile interval (ranging from 2.5% to 97.5%) is larger for the median than it is for the mean, at each sample size. In other words, when using the median, we are more uncertain what the true parameter value is than when we use the mean. Or, in other other words, we need fewer observations when using the mean to reach the same level of precision when using the median. In fact, it seems that the mean, at least in this scenario, is about 20% to 25% more efficient than the median.\n\n## Population vs. Sample\n\nRemember that our Pokémon weight model was based on the weights of the first 25 Pokémon. This is only a small sample of all Pokémon out there (our data has a total of 893). In the sample we observed, the average weight is 26.14. But what if we had instead focused on the next 25 Pokémon, from Raichu to Diglet? The average weight of these Pokémon is 20.68. That's a difference of 5.46.\n\nLet's actually take a look at the weights of all 893 Pokemon.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pokemon, aes(x = weight)) +\n  geom_histogram(color = \"black\", alpha = .75, binwidth = 25)\n```\n\n::: {.cell-output-display}\n![Weights of 893 Pokémon](understanding-regression-part-2_files/figure-html/fig-pokemon-weights-1.png){#fig-pokemon-weights width=672}\n:::\n:::\n\n\nThis figure shows the weights of *all* the Pokemon that are out there, and thus forms the population of Pokemon weights. Previously we took a *sample* from this population by only looking at 25 Pokemon of this population.\n\nNow imagine that we are not the only ones creating a Pokémon weight model. Instead, we are one of many who are doing so, and we all exchange our model information. We can tell others about our observation that weight = 26.144. In turn, others will give us their sample means. And let's further imagine that we also encounter people who used the median instead. Below I show some code to create these samples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples <- crossing(\n  estimator = c(\"mean\", \"median\"),\n  n = c(10, 25, 100),\n  i = 1:10000\n) %>%\n  rowwise() %>%\n  mutate(\n    estimate = if_else(\n      condition = estimator == \"mean\",\n      true = mean(sample(weights, n), na.rm = TRUE),\n      false = median(sample(weights, n), na.rm = TRUE)\n    )\n  )\n```\n:::\n\n\nLet's begin by simply looking at the distribution of mean values. The following graph contains 10,000 means, each based on 25 different Pokémon.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans25 <- filter(samples, estimator == \"mean\" & n == 25)\n\nggplot(means25, aes(x = estimate)) +\n  geom_density(alpha = .5, fill = \"black\") +\n  geom_vline(xintercept = mean(weights), linetype = \"dashed\") +\n  annotate(\"text\", x = 79, y = 0.0195, label = \"population mean\") +\n  labs(x = \"Sample mean\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![Distribution of 10,000 means based on 25 Pokémon each](understanding-regression-part-2_files/figure-html/fig-pokemon25-mean-weights-1.png){#fig-pokemon25-mean-weights width=672}\n:::\n:::\n\n\nThis distribution of means is also called a sampling distribution of means. In our case, we see that\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimators25 <- filter(samples, n == 25)\n\nggplot(estimators25, aes(x = estimate, fill = estimator)) +\n  geom_density(alpha = .75, adjust = 2) +\n  geom_vline(xintercept = mean(weights), linetype = \"solid\") +\n  geom_vline(xintercept = median(weights), linetype = \"dashed\") +\n  annotate(\n    geom = \"text\",\n    x = mean(weights),\n    y = 0.0465,\n    label = \"population mean\"\n  ) +\n  annotate(\n    geom = \"text\",\n    x = median(weights),\n    y = 0.049,\n    label = \"population median\",\n  ) +\n  labs(x = \"Sample mean\", y = \"Count\") +\n  scale_fill_viridis(option = \"mako\", discrete = TRUE, begin = .25, end = .75) +\n  coord_cartesian(ylim = c(0, 0.0425), clip = \"off\") +\n  theme(\n    plot.margin = unit(c(2, 1, 1, 1), \"lines\")\n  )\n```\n\n::: {.cell-output-display}\n![](understanding-regression-part-2_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n### T-distribution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- 30\npopulation <- tibble(population = rt(10000, df = df, ncp = 1))\n\nggplot(population, aes(x = population)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](understanding-regression-part-2_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndf <- crossing(\n  n = c(5, 10, 25, 50, 100, 250),\n  i = 1:10000\n) %>%\n  rowwise() %>%\n  mutate(\n    median = median(rt(n = n, df = df)),\n    mean = mean(rt(n = n, df = df))\n  ) %>%\n  pivot_longer(cols = c(median, mean), names_to = \"statistic\")\n\nggplot(df, aes(x = value)) +\n  # geom_density(mapping = aes(x = population), data = population, alpha = .4) +\n  geom_density(mapping = aes(fill = statistic), alpha = .5) +\n  facet_wrap(~n, scales = \"free\") +\n  scale_fill_viridis(option = \"mako\", discrete = TRUE, begin = .25, end = .75) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](understanding-regression-part-2_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sn)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: stats4\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'sn'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lubridate':\n\n    dst\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    sd\n```\n:::\n\n```{.r .cell-code}\npopulation <- rsn(1000, 5, 2, 5)\n\ndf <- crossing(\n  n = c(5, 10, 25, 50, 100, 250),\n  i = 1:1000\n) %>%\n  rowwise() %>%\n  mutate(\n    median = median(rnorm(n = n, mean = 0, sd = 1)),\n    mean = mean(rnorm(n = n, mean = 0, sd = 1))\n  ) %>%\n  pivot_longer(cols = c(median, mean), names_to = \"statistic\")\n\nggplot(df, aes(x = value, fill = statistic)) +\n  geom_histogram(binwidth = .05, alpha = .9) +\n  facet_wrap(~n, scales = \"free\") +\n  scale_fill_viridis(option = \"mako\", discrete = TRUE, begin = .25, end = .75) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](understanding-regression-part-2_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::",
    "supporting": [
      "understanding-regression-part-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}