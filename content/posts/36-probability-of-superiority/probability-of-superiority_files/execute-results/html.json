{
  "hash": "02cbfacbd7160ba231c3c55774f026b0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Probability of superiority\"\ndate: 2024-03-20\ncategories:\n  - statistics\n  - effect size\n  - probability of superiority\ncode-tools: true\ncode-fold: show\ndraft: true\n---\n\n\nRun the following setup code if you want to follow along.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(effectsize)\nlibrary(RProbSup)\nlibrary(brms)\nlibrary(tidybayes)\n```\n:::\n\n\n## Manually calculating PSup\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- c(1, 2, 3, 4, 5)\nb <- c(2, 3, 4, 5, 6)\n\nn <- length(a)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nouter(a, b, \">\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      [,1]  [,2]  [,3]  [,4]  [,5]\n[1,] FALSE FALSE FALSE FALSE FALSE\n[2,] FALSE FALSE FALSE FALSE FALSE\n[3,]  TRUE FALSE FALSE FALSE FALSE\n[4,]  TRUE  TRUE FALSE FALSE FALSE\n[5,]  TRUE  TRUE  TRUE FALSE FALSE\n```\n\n\n:::\n:::\n\n\nThe output is a matrix with the results of a comparison between each element of `a` and `b`. For example, the result in row 1 and column is `FALSE`, indicating that the first element of `a` (1) is not larger than the first element of `b` (2). Another example, the result in row 3 column 1 is `TRUE` because the third element of `a` (3) is larger than the first element of `b` (1).\n\nNext, we need to count the number of times that an element in `a` is larger than an element in `b`. This is easily done by using `sum()` on the matrix. This works because `TRUE`s are treated as 1 and `FALSE`s as 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(outer(a, b, \">\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6\n```\n\n\n:::\n:::\n\n\nIt's possible that two elements are tied (i.e., have the exact same value). To deal with this, we count the number of times this happens and divide the results by 2, thereby saying that ties are treated as one value being larger than the other half the time.\n\nWe sum both of these comparisons and then divide by the total number of comparisons (`n * n`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(sum(outer(a, b, \">\")) + 0.5 * sum(outer(a, b, \"==\"))) / (n * n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.32\n```\n\n\n:::\n:::\n\n\nThe result is the probability of superiority.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# n <- 10\n# x1 <- rnorm(n)\n# x2 <- x1 - rnorm(n, mean = 1)\n# # x2 <- x1\n# m <- cbind(c(x1, x2), c(rep(1, n), rep(2, n)))\n\n# A(m, 1, 2)\n\n\n# n1 <- length(x1)\n# n2 <- length(x2)\n# r1 <- sum(rank(c(x1, x2))[1:n1])\n# (r1 / n1 - (n1 + 1) / 2) / n2\n\n# (sum(outer(x1, x2, \">\")) + 0.5 * sum(outer(x1, x2, \"==\"))) / (n1 * n2)\n\n# wilcox.test(x1, x2)$statistic / (n1 * n2)\n\n# p_superiority(x1, x2, parametric = FALSE)\n\n# data <- tibble(\n#   id = 1:200,\n#   group = rep(c(\"a\", \"b\"), each = n),\n#   outcome = c(x1, x2)\n# )\n\n# p_superiority(outcome ~ group, data = data, parametric = FALSE)\n\n# model <- brm(outcome ~ group, data = data)\n\n# draws <- data |>\n#   add_predicted_draws(model, value = \"predicted_outcome\")\n\n# p_sups <- draws |>\n#   group_by(.draw) |>\n#   summarize(\n#     p_sup = p_superiority(\n#       predicted_outcome ~ group,\n#       parametric = FALSE\n#     )$p_superiority\n#   )\n\n# median_qi(p_sups, p_sup)\n\n# ggplot(p_sups, aes(x = p_sup)) +\n#   geom_histogram()\n\n# ggplot(draws, aes(x = .epred, fill = group)) +\n#   geom_histogram(position = \"identity\")\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}