[
  {
    "objectID": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html",
    "href": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html",
    "title": "Bayesian tutorial: Intercept-only model",
    "section": "",
    "text": "This post is the first of a series of tutorial posts on Bayesian statistics. I’m not an expert on this topic, so this tutorial is partly, if not mostly, a way for me to figure it out myself.\nThe goal will be to go through each step of the data analysis process and make things as intuitive and clear as possible. I’ll use the brms package to run the models and I will rely heavily on the book Statistical Rethinking by Richard McElreath.\nThe basic idea behind Bayesian statistics is that we start off with prior beliefs about the parameters in the model and then update those beliefs using the data. That means that for all subsequent models you need to figure out what your beliefs are before running any analyses. This is very different from frequentist statistics and probably the most off-putting part of running Bayesian analyses. However, my goal is to make this relatively easy by focusing on visualizing priors and how they change as a function of the Bayesian process. I’ll also try to come up with some methods to simplify the construction of priors, with the goal to have them be reasonable and non-controversial.\nIn some cases I might not even use a prior I personally believe in. Instead I’ll use a prior that represents a particular position or skepticism so that the results of the analysis can be used to change the mind of the skeptic, rather than me changing whatever I happen to believe.\nWith this in mind, let’s begin."
  },
  {
    "objectID": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#setup",
    "href": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#setup",
    "title": "Bayesian tutorial: Intercept-only model",
    "section": "Setup",
    "text": "Setup\nIn the code chunk below I show some setup code to get started, starting with the packages. After loading the packages I set the default ggplot2 theme and create a color palette consisting of two colors. Finally, I set a brms specific option to automatically re-run models if a model has changed. If not, the results will be read from a file to speed things up.\n\n\nCode\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(marginaleffects)\n\ntheme_set(theme_minimal())\ncolors <- c(\"#93CFDB\", \"#1E466E\")\n\noptions(brms.file_refit = \"on_change\")"
  },
  {
    "objectID": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#data",
    "href": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#data",
    "title": "Bayesian tutorial: Intercept-only model",
    "section": "Data",
    "text": "Data\nThe data I’ll play with is the same data Richard McElreath uses in Chapter 4 of his amazing book Statistal Rethinking. The data consists of partial census data of the !Kung San, compiled from interviews conducted by Nancy Howell in the late 1960s. Just like in the book, I will focus only on people 18 years or older.\n\n\nCode\ndata <- read_csv(\"Howell1.csv\")\ndata <- filter(data, age >= 18)\n\nhead(data)\n\n\n\n\nPartial census data for the Dobe area !Kung San compiled by Nancy Howell in the late 1960s. \n\n\nheight\nweight\nage\nmale\n\n\n\n\n151.765\n47.82561\n63\n1\n\n\n139.700\n36.48581\n63\n0\n\n\n136.525\n31.86484\n65\n0\n\n\n156.845\n53.04191\n41\n1\n\n\n145.415\n41.27687\n51\n0\n\n\n163.830\n62.99259\n35\n1"
  },
  {
    "objectID": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#an-intercept-only-model",
    "href": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#an-intercept-only-model",
    "title": "Bayesian tutorial: Intercept-only model",
    "section": "An intercept-only model",
    "text": "An intercept-only model\nLet’s focus the first question on the heights in the data. What are the heights of the Dobe area !Kung San?\nThe way to address this question is by constructing a model in which heights are regressed on only the intercept, i.e., an intercept-only model. You may be familiar with the R formula for this type of model: height ~ 1.\nWith this formula and the data we can use brms to figure out which priors we need to set by running the get_prior() function. This is probably the easiest way to figure which priors you need when you’re just starting out using brms.\n\n\nCode\nget_prior(height ~ 1, data = data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprior\nclass\ncoef\ngroup\nresp\ndpar\nnlpar\nlb\nub\nsource\n\n\n\n\nstudent_t(3, 154.3, 8.5)\nIntercept\n\n\n\n\n\n\n\ndefault\n\n\nstudent_t(3, 0, 8.5)\nsigma\n\n\n\n\n\n0\n\ndefault\n\n\n\n\n\n\nThe output shows us that we need to set two priors, one for the Intercept and one for sigma. brms already determined a default prior for each parameter (they are required for a Bayesian analysis), so we could immediately run an analysis if we want to but it is recommended to construct your own priors.\nAlso, using the get_prior() function is not the best way to think about which priors we need. Using the function will give us the answer, but it doesn’t really improve our understanding of why these two priors are needed. In this case I also omitted an important specification of the heights, which is that they are normally distributed (the default assumption in get_prior()). So let’s instead write down the model in a different way, which explicitly specifies how we think the heights are distributed and which parameters we need to set priors on. If we think the heights are normally distributed, we define our model like this:\n\\[heights_i ∼ Normal(\\mu, \\sigma)\\]\nWe explicitly note that the individual heights come from a normal distribution, which is determined by the parameters \\(\\mu\\) and \\(\\sigma\\). This then also immediately tells us that we need to set two priors, one on \\(\\mu\\) and one on \\(\\sigma\\).\nIn our intercept-only model, the \\(\\mu\\) parameter refers to our intercept and the \\(\\sigma\\) parameter refers to, well, sigma. Sigma is not often discussed in the literature I’m familiar with, but we’ll figure it out below. In fact, let’s discuss each of these parameters in turn and figure out what kind of prior makes sense."
  },
  {
    "objectID": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#the-intercept-mu-prior",
    "href": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#the-intercept-mu-prior",
    "title": "Bayesian tutorial: Intercept-only model",
    "section": "The intercept (\\(\\mu\\)) prior",
    "text": "The intercept (\\(\\mu\\)) prior\nThe prior for the intercept indicates what I believe the average height of the !Kung San to be.\nbrms has set the default intercept prior as a Student t-distribution with 3 degrees of freedom, a mean of 154.3 and a standard deviation of 8.5. That means brms starts off with a ‘belief’ that the average of the heights is 154.3, but with quite some uncertainty reflected in the standard deviation of 8.5 and the fact that the distribution is a Student t-distribution. A Student t-distribution has thicker tails compared to a normal distribution, meaning that numbers in the tails of the distribution are more likely compared to a normal distribution, at least when the degrees of freedom are low. At higher degrees of freedom, the t-distribution becomes more and more like the normal distribution. So, the thicker tails of the t-distributions means smaller and taller average heights are relatively more plausible.\nBut this is the default prior. brms determines this prior by peeking at the data to create a weak prior that is easily updated by the data. We can generally do better than the default priors, which is why it is recommended to create our own.\nSo what do I believe the average height to be? As a Dutch person, I might be under the impression that the average height is around 175 centimeters. This is probably too tall to use as an average for the !Kung San because we’re known for being quite tall. So I think the average should be lower than 175, perhaps 170. I am not very sure, though. After all, I am far from an expert on people’s heights; I am only using my layman knowledge here. An average of 165 seems possible to me too. So let’s describe my belief in the form of a distribution in which multiple averages are possible, to varying extents. We should use a Student t-distribution with small degrees of freedom if we want to allow for the possibility of being very wrong (remember, it has thicker tails, so it assigns more probability to a wider range of average heights). We’re not super uncertain about people’s heights, though, so let’s use a normal distribution.\nAs we saw in defining our height model, a normal distribution requires that we set two parameters: the \\(\\mu\\) and the \\(\\sigma\\). The \\(\\mu\\) we already covered (i.e., 170), so that leaves \\(\\sigma\\). Let’s set this to 10 and see what happens by visualizing this prior. Below I plot both the default brms prior and our own with \\(\\mu\\) = 170 and \\(\\sigma\\) = 10.\n\n\nCode\nheight_prior_intercept <- tibble(\n  height_mean = seq(from = 100, to = 250, by = 0.1),\n  mine = dnorm(height_mean, mean = 170, sd = 10),\n  default = dstudent_t(height_mean, df = 30, mu = 154.3, sigma = 8.5),\n)\n\nheight_prior_intercept <- pivot_longer(\n  height_prior_intercept,\n  cols = -height_mean,\n  names_to = \"prior\"\n)\n\nggplot(\n  height_prior_intercept,\n  aes(x = height_mean, y = value, linetype = fct_rev(prior))\n) +\n  geom_line() +\n  labs(x = \"Average height\", y = \"\", linetype = \"Prior\") +\n  scale_x_continuous(breaks = seq(100, 250, 20))\n\n\n\n\n\nTwo priors for \\(\\mu\\)\n\n\n\n\nMy prior indicates that I believe the average height to be higher than the default prior. In terms of the standard deviation, we both seem to be about equally uncertain about this average. Looking at this graph I think this prior of mine is not very plausible. Apparently I assign quite a chunk of plausibility to an average of 180 cm, or even 190 cm, which is very unlikely. An average of 160 cm is more plausible to me than an average of 180, so I should probably lower the mu, or use more of a skewed distribution. This is one of the benefits of visualizing the prior, it can make you think again about your prior so that you may improve on it. Based on the graph, I will change the mean of my prior to 160. I can probably also lower the standard deviation, but I’ll leave it at 10 to show how easily the data will update this prior."
  },
  {
    "objectID": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#the-sigma-sigma-prior",
    "href": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#the-sigma-sigma-prior",
    "title": "Bayesian tutorial: Intercept-only model",
    "section": "The sigma (\\(\\sigma\\)) prior",
    "text": "The sigma (\\(\\sigma\\)) prior\nWhat about the sigma prior? What even is sigma? Sigma is the estimated standard deviation of the errors or, in other words, the standard deviation of the residuals of the model. In the simple case of an intercept-only model, this is identical to the standard deviation of the outcome (heights, in this case).\nI think setting the standard deviation of the distribution of heights (not the mean of the heights) is quite difficult. There are parts that are easy, such as the fact that the standard deviation has to be 0 or larger (it can’t be negative), but exactly how large it should be, I don’t know.\nI do know it is unlikely to be close to 0, and unlikely to be very large. That’s because I know people’s heights do vary, so I know the sigma can’t be 0. I also know it’s not super large because we don’t see people who are taller than 2 meters very often. This means the peak of our prior should be somewhere above 0, with a tail to allow higher values but not too high. We can use a normal distribution for this with a mean above 0 and a particular standard deviation, and ignore everything that’s smaller than 0 (brms automatically ignores negative values for \\(\\sigma\\)).\nAs I mentioned before, there is a downside of using a normal distribution, though. Normal distributions have long tails, but there is actually very little density in those tails. If we are quite uncertain about our belief about sigma, we should use a t-distribution, or perhaps even a cauchy distribution (actually, the cauchy distribution is a special case of the t-distribution; they are equivalent if the degree of freedom is 1). The lower the degrees of freedom, the more probability we assign to higher and lower values.\nA t-distribution requires three parameters: \\(\\mu\\), \\(\\sigma\\), and the degrees of freedom. I set \\(\\mu\\) to 5, \\(\\sigma\\) to 5, and the degrees of freedom to 1. Below I plot this prior and brms’s default prior to get a better grasp of these priors.\n\n\nCode\nheight_prior_sigma <- tibble(\n  height_sigma = seq(from = 0, to = 50, by = .1),\n  default = dstudent_t(height_sigma, df = 3, mu = 0, sigma = 8.5),\n  mine = dstudent_t(height_sigma, df = 1, mu = 5, sigma = 5)\n)\n\nheight_prior_sigma <- pivot_longer(\n  height_prior_sigma,\n  cols = -height_sigma,\n  names_to = \"prior\"\n)\n\nggplot(\n  height_prior_sigma,\n  aes(x = height_sigma, y = value, linetype = fct_rev(prior))\n) +\n  geom_line() +\n  labs(x = \"Standard deviation of heights\", y = \"\", linetype = \"Prior\")\n\n\n\n\n\nTwo priors for \\(\\sigma\\)\n\n\n\n\nAs you can see, both distributions have longish tails, allowing for the possibility of high standard deviations. There are some notable differences between the two priors, though. Our prior puts more weight on a standard deviation larger than 0, while the default prior reflects a belief in which a standard deviation of 0 is most likely. However, both priors are quite weak."
  },
  {
    "objectID": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#prior-predictive-check",
    "href": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#prior-predictive-check",
    "title": "Bayesian tutorial: Intercept-only model",
    "section": "Prior predictive check",
    "text": "Prior predictive check\nSo far we have inspected each prior in isolation, but we can also use our priors to simulate heights and see if the distribution of heights makes sense. This is called a prior predictive check.\nI’ll use brms to do this by running the brm() function. The brm() function is the main work horse of the brms package. It allows us to run Bayesian analyses by using a common notation style familiar to those who use R. This is also one of the reasons why the brms package is so great; it’s very easy to get started with running Bayesian analyses.\nThe brm() function requires a model specification and the data. Optionally, but usefully, we should also specify the response distribution (a normal distribution by default) and the priors.\nHowever, we’re not ready to actually run the model just yet. Instead, we will kinda trick brms into running an analysis, but tell it to only sample from the prior using the sample_prior argument. This will enable us to get ‘predicted’ responses based entirely on our priors and not the data.\nAdditionally, we also set the number of cores to speed up the analysis, a seed to make the results reproducible, and a file to store the results into so that if we run the analysis again, we can simply read the results from the file rather than running the analysis again.\n\n\nCode\nmodel_height_prior <- brm(\n  height ~ 1,\n  data = data,\n  family = gaussian,\n  prior = c(\n    prior(normal(160, 10), class = \"Intercept\"),\n    prior(cauchy(5, 5), class = \"sigma\")\n  ),\n  sample_prior = \"only\",\n  cores = 4,\n  seed = 4,\n  file = \"models/model_height_prior.rds\"\n)\n\n\nThe next part is a little odd because we will visualize the distribution of predicted heights by visualizing draws from this distribution (as opposed to some analytic formula that describes the distribution). By default, brms will draw 4000 draws. We could use the predict() function to do this (e.g., predict(model_height_prior), but I prefer to use the marginaleffects package because it’s a really nice package that will simplify things further down the road.\nThe marginaleffects function to use is predictions() and posterior_draws(). The predictions() function takes a model object and optionally a new data frame to create predictions for each row in the data frame. This is a little tricky because by default it will use the data from the model itself, which would create a new data frame that has rows equal to the number of rows in the original data frame. This is not needed in our case because we’re only interested in a single number (the average height). On top of that, after running the predictions() function we want to run the posterior_draws() function to obtain the draws of the posterior so that we can visualize it. If we get the predictions of every single row in the original data frame, we would end up with a new data frame with rows equal to the number of rows in the original data frame times the number of draws (4000 by default). We don’t want to have such a large data frame. So, because we’re dealing with an intercept-only model that has no predictors, we will create an almost empty data frame. I want to re-use these results later to compare the prior to the posterior results, so I’ll simply add a column in this almost empty data frame to say that these results are from a prior distribution. After getting the predictions, we use the posterior_draws() function to obtain the draws.\n\n\nCode\nheights_prior <- model_height_prior %>%\n  predictions(newdata = tibble(distribution = \"prior\"), type = \"prediction\") %>%\n  posterior_draws()\n\nggplot(heights_prior, aes(x = draw)) +\n  geom_histogram(binwidth = 1, alpha = .85) +\n  xlim(100, 250) +\n  labs(x = \"Height\", y = \"\")\n\n\n\n\n\nPrior predictive check\n\n\n\n\nOur priors result in a normal distribution of heights with the bulk of the observations ranging from about 125 cm to 200 cm. That seems fairly reasonable to me, as someone who doesn’t know too much about the heights of the !Kung San."
  },
  {
    "objectID": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#running-the-model",
    "href": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#running-the-model",
    "title": "Bayesian tutorial: Intercept-only model",
    "section": "Running the model",
    "text": "Running the model\nNow that the priors are in order we can run the model with the code below. Notice that this time I omit the sample_prior argument so we only obtain the posterior results.\n\n\nCode\nmodel_height <- brm(\n  data = data,\n  family = gaussian,\n  height ~ 1,\n  prior = c(\n    prior(normal(160, 10), class = \"Intercept\"),\n    prior(cauchy(5, 5), class = \"sigma\")\n  ),\n  cores = 4,\n  seed = 4,\n  file = \"models/model_height.rds\"\n)\n\n\nAfter running the model, we first check whether the chains look like caterpillars because that indicates we have samples from the entire distribution space of the posteriors.\n\n\nCode\nplot(model_height)\n\n\n\n\n\nThe chains look good.\nWe can call up the estimates and the 95% confidence intervals by printing the model object.\n\n\nCode\nsummary(model_height)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height ~ 1 \n   Data: data (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   154.62      0.42   153.78   155.47 1.00     2613     2354\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     7.76      0.30     7.21     8.37 1.00     3290     2585\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nHere we see the Intercept and sigma estimates. Apparently our posterior estimate for the Intercept is 154.62 and the estimate for \\(\\sigma\\) is 7.76. We also see the 95% CIs, but let’s visualize these results instead.\nInspecting the chains also showed us the posterior distributions of the two parameters, but let’s create our own graphs that compare both the prior and posterior distributions. We can use the as_draws_df() function from brms to get draws from each parameter in the model. In the code below I do that twice, once to get the draws from our previous model that sampled from the prior only and once from our new model. The result for each is a data frame and I’ll add a column to indicate whether the draw is from the prior or posterior.\n\n\nCode\ndraws_prior <- model_height_prior %>%\n  as_draws_df() %>%\n  mutate(distribution = \"prior\")\n\ndraws_posterior <- model_height %>%\n  as_draws_df() %>%\n  mutate(distribution = \"posterior\")\n\ndraws <- bind_rows(draws_prior, draws_posterior)\n\nggplot(draws, aes(x = b_Intercept, fill = fct_rev(distribution))) +\n  geom_histogram(binwidth = 1, position = \"identity\", alpha = .85) +\n  xlim(145, 195) +\n  labs(\n    x = \"Intercept (i.e., average height)\",\n    y = \"\",\n    fill = \"Distribution\"\n  ) +\n  scale_fill_manual(values = colors)\n\n\n\n\n\nHere we see that the posterior distribution of average heights is much more narrow and centered around 155 cm. So not only should we switch from thinking the average is lower than 160, we can also be much more confident about the mean.\nHow about sigma?\n\n\nCode\nggplot(draws, aes(x = sigma, fill = fct_rev(distribution))) +\n  geom_histogram(binwidth = 0.25, position = \"identity\", alpha = .85) +\n  xlim(0, 25) +\n  labs(\n    x = \"Sigma (i.e., height standard deviation)\",\n    y = \"\",\n    fill = \"Distribution\"\n  ) +\n  scale_fill_manual(values = colors)\n\n\n\n\n\nSimilarly, we see that the posterior for sigma is also much more narrow and around 8.\nA final step is to conduct a posterior predictive check. Since we also conducted a prior predictive check we can plot both and compare how our overall beliefs about the distribution of heights should change as a function of the data. Below I create a new data frame with draws from the posterior, just like when I created the prior predictive check, and merge it with the prior data frame from before.\n\n\nCode\nheights_posterior <- model_height %>%\n  predictions(newdata = tibble(distribution = \"posterior\"), type = \"prediction\") %>%\n  posterior_draws()\n\nheights <- bind_rows(heights_prior, heights_posterior) %>%\n  mutate(distribution = fct_relevel(distribution, \"prior\"))\n\nggplot(heights, aes(x = draw, fill = distribution)) +\n  geom_histogram(binwidth = 1, alpha = .85, position = \"identity\") +\n  xlim(100, 250) +\n  labs(x = \"Height\", y = \"\", fill = \"Distribution\") +\n  scale_fill_manual(values = colors)\n\n\n\n\n\nPrior and posterior predictive check\n\n\n\n\nAnd that’s it!"
  },
  {
    "objectID": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#summary",
    "href": "content/posts/5-bayesian-tutorial-intercept-only/bayesian-tutorial-intercept-only.html#summary",
    "title": "Bayesian tutorial: Intercept-only model",
    "section": "Summary",
    "text": "Summary\nIn this post I showed how to run an intercept-only model in brms. It consisted of the following steps:\n\nDefine the model\nUse the model to figure out which priors to set\nVisualize the priors and create a prior predictive check to potentially tweak the priors\nRun the model using brms\nInspect the output of brms, including the chains\nObtain draws of the estimates and visualize their distribution\nCompare the prior predictive check to the posterior results to see how much to update based on the data\n\nIn the next post I’ll show how to add a predictor to the model.\nThis post was last updated on 2023-05-10."
  },
  {
    "objectID": "content/posts/18-bayesian-tutorial-simple-regression/bayesian-tutorial-simple-regression.html",
    "href": "content/posts/18-bayesian-tutorial-simple-regression/bayesian-tutorial-simple-regression.html",
    "title": "Bayesian tutorial: Single predictor regression",
    "section": "",
    "text": "In my previous blog post I showed how to use brms and tidybayes to run an intercept-only model. Now let’s extend that model by adding a predictor.\nThe data is the same as in the previous post (including the filter that we only focus on people 18 years or older). This data contains weight data as well as height data, so that means we can run a model in which we regress heights onto weights, i.e., a regression with a single predictor.\nIf you want to follow along, run the following setup code."
  },
  {
    "objectID": "content/posts/18-bayesian-tutorial-simple-regression/bayesian-tutorial-simple-regression.html#adding-a-single-predictor",
    "href": "content/posts/18-bayesian-tutorial-simple-regression/bayesian-tutorial-simple-regression.html#adding-a-single-predictor",
    "title": "Bayesian tutorial: Single predictor regression",
    "section": "Adding a single predictor",
    "text": "Adding a single predictor\nThe formula syntax for a model in which we regress heights onto weights is height ~ weight. We can use this formula in get_prior() to see which priors we need to specify.\n\n\nCode\nget_prior(height ~ weight, data = data)\n\n\n                    prior     class   coef group resp dpar nlpar lb ub\n                   (flat)         b                                   \n                   (flat)         b weight                            \n student_t(3, 154.3, 8.5) Intercept                                   \n     student_t(3, 0, 8.5)     sigma                               0   \n       source\n      default\n (vectorized)\n      default\n      default\n\n\nThe output is a bit trickier compared to the intercept-only model output. There’s the Intercept and sigma priors again, as well as two extra rows referring to a class called b. These two rows actually refer to the same prior, one refers specifically to the weight predictor and one refers to all predictors. If you run a model with many more predictors, you could set one prior that applies to all predictors. In this case though, we only have 1 predictor so it actually doesn’t matter, both refer to the same prior.\nRecall from the previous post that I said writing down your model explicitly is a better way to understand what you’re doing, so let’s go ahead and do that.\n\\[\\displaylines{heights_i ∼ Normal(\\mu_i, \\sigma) \\\\ \\mu_i = \\alpha + \\beta x_i}\\]\nWe again specify that the heights are normally distributed, so we still have a \\(\\mu\\) and \\(\\sigma\\), but this time the \\(\\mu\\) is no longer a parameter to estimate. Instead, it’s constructed from other parameters, \\(\\alpha\\), \\(\\beta\\), and an observed variable \\(x_i\\) (the weight observations).\nIf you’re used to linear regression equations, this notation should not surprise you. \\(\\alpha\\) refers to the intercept and \\(\\beta\\) to the slope.\nWe need to set priors on these parameters. The prior for \\(\\alpha\\) can be the same as the prior for \\(\\mu\\) from the previous intercept-only model, if we center the data so the intercept refers to the average height of someone with an average weight, rather than someone with 0 weight (the default, which makes no sense). So let’s first mean center the weight observations.\n\n\nCode\ndata <- mutate(data, weight_mc = weight - mean(weight))\n\n\nNow we can use the same prior as before, which was a normal distribution with a mean of 160 and a standard deviation of 10 (assuming we did not update this as a result of the previous analysis).\nNext is the prior for the slope. This represents the relationship between weights and heights. For every 1 increase in weight, how much do we think that the height will increase or decrease? We could begin with an agnostic prior in which we do not specify the direction and instead just add some uncertainty so the slope can go in either direction. For example, let’s put a normal distribution on the slope with a mean of 0 and a standard deviation of 10.\nFinally, we have the prior for sigma (\\(\\sigma\\)). To remind you, sigma refers to the standard deviation of the errors or the residual standard deviation. Now that we have a predictor that means the sigma can be less than what it was in the intercept-only model because some of the variance in heights might be explained by the weights, decreasing the size of the residuals and therefore sigma. So, if we believe in a relationship between heights and weights, we should change our prior for sigma so that it’s lower. Given that we used a prior for the slope that is agnostic (there could be a positive, negative, or no relationship), our prior for sigma could be left unchanged because it was broad enough to allow for these possibilities."
  },
  {
    "objectID": "content/posts/18-bayesian-tutorial-simple-regression/bayesian-tutorial-simple-regression.html#prior-predictive-check",
    "href": "content/posts/18-bayesian-tutorial-simple-regression/bayesian-tutorial-simple-regression.html#prior-predictive-check",
    "title": "Bayesian tutorial: Single predictor regression",
    "section": "Prior predictive check",
    "text": "Prior predictive check\nWe can again create a prior predictive check to see whether our priors actually make sense. However, instead of plotting the predicted distribution of heights, we’re mostly interested in the relationship between weight and height, so we should plot a check of that relationship instead. We could simulate our own data like I did in the previous post or we can just run the Bayesian model and only draw from the prior, which I also did in the previous post and will do so again here.\n\n\nCode\nmodel_height_weight_prior <- brm(\n  height ~ weight_mc,  \n  data = data, \n  family = gaussian,\n  prior = c(\n      prior(normal(160, 10), class = \"Intercept\"),\n      prior(cauchy(5, 5), class = \"sigma\"),\n      prior(normal(0, 10), class = \"b\")\n    ), \n  sample_prior = \"only\",\n  cores = 4,\n  seed = 4,\n  file = \"models/model_height_weight_prior.rds\"\n)\n\n\nWith this model we can use the spread_draws() function from the tidybayes package to get draws from the posterior distribution of the intercept and slope parameters. With an intercept and slope we can visualize the relationship we’re interested in. Remember, though, that brms will give you 4000 draws by default from the posteriors. In other words, you get 4000 intercepts and slopes. That’s a bit much to visualize, so let’s only draw 100 intercepts and slopes.\nTo help make sense of the sensibility of the slopes I’ve added the average weight to the weights so we’re back on the normal scale and not the mean centered scale and I’ve added two dashed lines to indicate the minimum and maximum height we can expect.\n\n\nCode\ndraws <- spread_draws(\n  model_height_weight_prior, b_Intercept, b_weight_mc, ndraws = 100\n)\n\nweight_mean <- data %>%\n  pull(weight) %>%\n  mean()\n\nggplot(data, aes(x = weight_mc, y = height)) +\n  geom_blank() +\n  geom_abline(\n    data = draws,\n    mapping = aes(intercept = b_Intercept, slope = b_weight_mc),\n    alpha = .25\n  ) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_hline(yintercept = 272, linetype = \"dashed\") +\n  geom_label(x = 0, y = 260, label = \"Tallest person ever\") +\n  labs(x = \"Weight\", y = \"Height\") +\n  scale_x_continuous(labels = function(x) round(x + weight_mean))\n\n\n\n\n\nA prior predictive check of the relationship between weight and height\n\n\n\n\nThe plot shows a wide range of possible slopes, some of which are definitely unlikely because they lead to heights that are smaller than 0 or higher than the tallest person who ever lived. We should lower our uncertainty by reducing the standard deviation on the prior. In the next model I lower it to 3.\nAdditionally, the negative slopes are all pretty unlikely because we should expect a positive relationship between weight and height (taller people tend to be heavier). We could therefore also change our prior to force it to be positive using the lb argument in our prior for b or use a distribution that doesn’t allow for any negative values. Let’s not do this though. Let’s assume we have no idea whether the relationship will be positive or negative and instead focus on the standard deviation instead so that we don’t obtain relationships we definitely know are unlikely.\n\n\nCode\nmodel_height_weight_prior_2 <- brm(\n  height ~ weight_mc,  \n  data = data, \n  family = gaussian,\n  prior = c(\n      prior(normal(160, 10), class = \"Intercept\"),\n      prior(cauchy(5, 5), class = \"sigma\"),\n      prior(normal(0, 3), class = \"b\")\n    ), \n  sample_prior = \"only\",\n  cores = 4,\n  seed = 4,\n  file = \"models/model_height_weight_prior_2.rds\"\n)\n\n\nLet’s inspect the lines again.\n\n\nCode\ndraws <- spread_draws(\n  model_height_weight_prior_2, b_Intercept, b_weight_mc, ndraws = 100\n)\n\nggplot(data, aes(x = weight_mc, y = height)) +\n  geom_blank() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_hline(yintercept = 272, linetype = \"dashed\") +\n  geom_abline(\n    data = draws,\n    mapping = aes(intercept = b_Intercept, slope = b_weight_mc),\n    alpha = .25\n  ) +\n  geom_label(x = 0, y = 260, label = \"Tallest person ever\") +\n  labs(x = \"Weight\", y = \"Height\") +\n  scale_x_continuous(labels = function(x) round(x + weight_mean))\n\n\n\n\n\nA prior predictive check of the relationship between weight and height\n\n\n\n\nThis looks a lot better, so let’s run the model for real now.\n\n\nCode\nmodel_height_weight <- brm(\n  data = data, \n  height ~ weight_mc,\n  family = gaussian,\n  prior = c(\n      prior(normal(160, 10), class = \"Intercept\"),\n      prior(cauchy(5, 5), class = \"sigma\"),\n      prior(normal(0, 3), class = \"b\", lb = 0)\n    ), \n  sample_prior = TRUE,\n  cores = 4,\n  seed = 4,\n  file = \"models/model_height_weight.rds\"\n)\n\nmodel_height_weight\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: height ~ weight_mc \n   Data: data (Number of observations: 352) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   154.60      0.27   154.07   155.12 1.00     4449     2862\nweight_mc     0.91      0.04     0.82     0.99 1.00     3876     3057\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     5.10      0.19     4.74     5.50 1.00     4567     3041\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe see that the estimate for the weight predictor is 0.91. For every increase of weight by 1 we can expect their height to increase by this number. We can also be fairly confident in this kind of relationship because the lower and upper bound of the 95% CI ranges from 0.82 to 0.99. These numbers are what we are usually interested in, but let’s also plot the the entire posterior for the slope estimate so can see the entire distribution and not just this summary. Let’s also add the prior so we can see how much that changed as a result of the data.\n\n\nCode\nresults <- model_height_weight %>%\n  gather_draws(prior_b, b_weight_mc) %>%\n  mutate(\n    distribution = if_else(\n      str_detect(.variable, \"prior\"), \"prior\", \"posterior\"\n    )\n  )\n\nggplot(results, aes(x = .value, fill = fct_rev(distribution))) +\n  geom_histogram(binwidth = 0.05, position = \"identity\", alpha = .85) +\n  xlim(0, 5) +\n  labs(x = \"Slope\", y = \"\", fill = \"Distribution\") +\n  scale_fill_manual(values = colors)\n\n\n\n\n\nApparently our prior was still very uninformed because the posterior shows we can be confident in a much narrower range of slopes!\nLet’s also create another plot in which we plot the slope and its posterior against the observed data. The way to do this is by first creating a data frame containing weights that we want to predict the heights for. The (mean-centered) weights in the data range from -13.92 to 18, so we can roughly use that same range.\nThen we use add_epred_draws() to predict the expected height for each of the weights we stored in the data frame. This is not a single value. Instead, we get a distribution of possible heights for each weight value. We could plot all of these distributions, for example by creating a shaded region at each weight representing how likely the height is, or we can summarize that distribution of heights for each weight. The tidybayes package has the median_qi() function to summarize a distribution to a point and interval. By default it uses the median for the point summary and a 5% and 95% quartile range for the interval; the same summary we saw in the output from brm.\n\n\nCode\nslopes_qi <- tibble(\n    weight_mc = seq(from = -15, to = 20, by = 1)\n  ) %>%\n  add_epred_draws(model_height_weight) %>%\n  median_qi()\n\nggplot() +\n  geom_ribbon(\n    mapping = aes(ymin = .lower, ymax = .upper, x = weight_mc),\n    data = slopes_qi,\n    alpha = .25\n  ) +\n  geom_line(\n    mapping = aes(x = weight_mc, y = .epred),\n    data = slopes_qi\n  ) + \n  geom_point(\n    mapping = aes(x = weight_mc, y = height),\n    data = data,\n    alpha = .25\n  ) +\n  labs(x = \"Weight\", y = \"Height\") +\n  scale_x_continuous(labels = function(x) round(x + weight_mean))\n\n\n\n\n\nThis graph is great because it shows us how confident we can be in the regression line. It does omit one source of uncertainty, though. The previous plot only shows the uncertainty about the regression line (the intercept and slope). We can also make a plot with predicted values of individual heights, which also incorporates the uncertainty from the \\(\\sigma\\) parameter.\n\n\nCode\npredicted_slopes_qi <- tibble(\n    weight_mc = seq(from = -20, to = 20, by = 1)\n  ) %>%\n  add_predicted_draws(model_height_weight) %>%\n  median_qi()\n\nggplot() +\n  geom_ribbon(\n    aes(ymin = .lower, ymax = .upper, x = weight_mc),\n    data = predicted_slopes_qi,\n    alpha = .25\n  ) +\n  geom_line(\n    aes(x = weight_mc, y = .prediction),\n    data = predicted_slopes_qi\n  ) + \n  geom_point(\n    aes(x = weight_mc, y = height),\n    data = data,\n    alpha = .25\n  ) +\n  labs(x = \"Weight\", y = \"Height\") +\n  scale_x_continuous(labels = function(x) round(x + weight_mean))\n\n\n\n\n\nWhile this graph is pretty cool, I haven’t ever seen one in a social psychology paper, probably because academic psychologists are mostly interested in the parameters (e.g., means, correlations) rather than predicting individual observations."
  },
  {
    "objectID": "content/posts/18-bayesian-tutorial-simple-regression/bayesian-tutorial-simple-regression.html#summary",
    "href": "content/posts/18-bayesian-tutorial-simple-regression/bayesian-tutorial-simple-regression.html#summary",
    "title": "Bayesian tutorial: Single predictor regression",
    "section": "Summary",
    "text": "Summary\nIn this post I showed how to run a single predictor model in brms. The addition of a predictor meant that the previous intercept-only model had to be updated by turning the \\(\\mu\\) parameter into a regression equation. This then required an additional prior for the slope. To help set a prior on the slope, I created a prior predictive check of the slope. Running the model itself was straightforward and I provided several visualizations to help understand the results, including visualizing the posteriors of the slope parameter, the slope across the range of weights, and individual predicted heights.\nIn the next post I’ll show how to use brms to analyze correlations."
  },
  {
    "objectID": "content/projects/animal-welfare/animal-welfare.html",
    "href": "content/projects/animal-welfare/animal-welfare.html",
    "title": "Animal welfare",
    "section": "",
    "text": "Now that I work at Rethink Priorities I get to devote a significant chunk of my time on projects related to animal welfare. I’ve only recently joined RP, though, so there is not much yet to show, but below I explain why I want to focus on this more and some steps I’ve taken so far."
  },
  {
    "objectID": "content/projects/animal-welfare/animal-welfare.html#why-is-this-important",
    "href": "content/projects/animal-welfare/animal-welfare.html#why-is-this-important",
    "title": "Animal welfare",
    "section": "Why is this important?",
    "text": "Why is this important?\n\n“It may come one day to be recognized, that the number of legs, the villosity of the skin, or the termination of the os sacrum, are reasons equally insufficient for abandoning a sensitive being to the same fate. What else is it that should trace the insuperable line? Is it the faculty of reason, or perhaps, the faculty for discourse?…the question is not, Can they reason? nor, Can they talk? but, Can they suffer?\n\nThis (partial) quote by Jeremy Bentham gets to the heart of the matter. Whether something deserves moral concern is predominantly (if not only) a function of whether that something is capable of suffering. Cheating on a partner is bad not because cheating is inherently bad, but because it likely causes great suffering on the cheated-on partner. If your partner doesn’t care about being cheated on (i.e., being in an open relationship), cheating is no longer a bad thing. This shows morality is about the consequences of one’s actions and whether those consequences cause suffering.\nMany animals can suffer. It is unclear and impossible with our current knowledge about consciousness to assess which animals are capable of suffering, but we know enough to confidently say that some animals can suffer. Large mammals such as cows, sheep, goats, and horses can undoubtedly suffer. Smaller creatures such as chicken and turkeys are similarly unlucky and likely also capable. It is less clear when it comes to fish, but I would put my money them being able to suffer rather than being experience-less creatures.\nThe examples of animals I used above are the kinds of animals we farm. These are the kinds of animals we treat in ways that cause them to suffer, with great intensity and in great numbers. Chicken, for example, live in crowded spaces that cause in-fighting, the spread of diseases, and deaths due to, for instance, pile ups. They are artificially selected to grow at unhealthily fast rates, causing physical abnormalities. They are prevented from displaying their instinctive behaviors, such as establishing pecking orders, dust bathing, building nests, and spreading their wings. Sometimes farmers address these problems, although not always in the animal’s best interest. Injuries due to in-fighting is reduced by cutting or burning off the beaks, thus preventing them from harming each other. Other farm animals face similar situations.\nWhat makes it worse is the scale of factory farming. In the Netherlands alone, over 600 million land animals were killed in 2019. And that’s just in the Netherlands, a pretty tiny country. In the U.S., 9.76 billion land animals were killed in 2020. These numbers are so big they almost lose their meaning. The reality is, however, that factory farming causing suffering in billions and billions of individual animals, every year.\nPeople might retort that killing animals for food is simply the natural order of things. This argument is easy to refute: The natural order also sucks. We should not look at nature to determine what is good or bad (this is called the naturalistic fallacy). In nature, all kinds of suffering takes place. Animals (including humans) die due to various causes including disease, disasters, predation, starvation, and so on. These things are normal in nature. As humans, we have done our best to remove all these natural threats from our lives because that reduces our suffering. If we want to be natural, we should invite all these threats back into our lives. Of course, that’s not what we want to do, because we don’t want to suffer.\nI think we should extent that courtesy also to wild animals. We have succeeded in making our lives a lot better, while ignoring the same problems in other species. If we care about the lives of conscious creatures (such as our fellow humans, our pets, our zoo animals), we should also care about the lives of wild animals.\nIn short, farm animals suffer in horrible ways in great numbers, and the same happens in nature (although perhaps less efficiently than in factory farms). Given that suffering is the main reason to care about something, this logically means that we should figure out ways to alleviate their suffering. I hope to contribute to this."
  },
  {
    "objectID": "content/projects/animal-welfare/animal-welfare.html#what-am-i-working-on",
    "href": "content/projects/animal-welfare/animal-welfare.html#what-am-i-working-on",
    "title": "Animal welfare",
    "section": "What am I working on?",
    "text": "What am I working on?\nAt Rethink Priorities I’m working on the development of a scale to assess people’s attitudes toward wild animal suffering. We aim to publish the results of this project in an academic journal with the goal for many other academics to begin studying the topic of wild animal suffering.\nI have also joined the following groups:\n\nSociety for the Psychology of Human-Animal Intergroup Relations (PHAIR)\nResearch to End Consumption of Animal Products (RECAP)\n\nBy joining these groups I hope to learn more about current research directions and to join existing projects. Eventually I also hope to use these platforms to share my own work.\nI’ve joined a project by Mercy for Animals on a multi-country survey to develop insights on people’s knowledge, attitudes, behavioral intentions and behaviors regarding farmed animal issues and key advocacy activities.\nI’ve started my own project that is a meta-analysis on meat intervention studies. There have been several meta-analyses on this topic (see here for a recent one), but I think I can contribute in some unique ways by creating a ‘live meta-analysis’ that can continuously be updated with new studies."
  },
  {
    "objectID": "content/projects/statcheck/statcheck.html",
    "href": "content/projects/statcheck/statcheck.html",
    "title": "statcheck",
    "section": "",
    "text": "Together with Michèle Nuijten I am working on improving statcheck. statcheck is a software tool to help researchers make fewer statistics-related typos."
  },
  {
    "objectID": "content/projects/statcheck/statcheck.html#why-is-this-important",
    "href": "content/projects/statcheck/statcheck.html#why-is-this-important",
    "title": "statcheck",
    "section": "Why is this important?",
    "text": "Why is this important?\nSimilar to my tidystats project, our aim is to address a particular problem in statistics reporting: the reporting of incorrect statistics.\nAs has been shown by Michèle and her colleagues, statistics are often reported incorrectly (Nuijten et al., 2016). This is likely due to the fact that researchers do not have the necessary software tools to reliably take the output of statistics from their data analysis software and enter it into their text editor. Instead, researchers are likely to copy statistics from the output by hand or by copy-pasting the output. Both techniques are error-prone, resulting in many papers containing statistical typos. This is a problem because statistical output is used in meta-analyses to aggregate the evidence for particular theories, which sometimes also inform policy. In some cases, the errors may even be so large that it affects the conclusion drawn from the statistical test."
  },
  {
    "objectID": "content/projects/statcheck/statcheck.html#what-am-i-working-on",
    "href": "content/projects/statcheck/statcheck.html#what-am-i-working-on",
    "title": "statcheck",
    "section": "What am I working on?",
    "text": "What am I working on?\nAdmittedly, I am simply joining Michèle and her efforts to help researchers make fewer typos. She and her colleagues have already done a lot of the work—we’re now just trying to make it even better. For example, Sacha Epskamp and Michèle developed statcheck. statcheck is an R package designed to catch statistical reporting mistakes. It works by first extracting statistics from a paper (e.g., t values, degrees of freedom, p-values). It then uses the test statistic and degrees of freedom to re-calculate the p-value and compare it to the reported p-value. If the two don’t match, there is probably a reporting mistake.\nYou can use the statcheck package in R to check your paper or you can use the web app. Using the web app consists of simply uploading your paper and checking the results. You can then go back to the paper and correct the mistakes.\nWith my experience creating tidystats, and particularly the tidystats Word add-in, we’ve started to create a Word add-in for statcheck. This add-in allows researchers to scan their document for statistical inconsistencies, find them, and fix them. This add-in is currently in beta and we hope to release it soon.\nWe are also working on improving statcheck together with the eScience Center. Together with their help we hope to expand statcheck so it can catch a greater variety of statistical inconsistencies. We have had some preparatory meetings with them and plan to fully begin this project soon."
  },
  {
    "objectID": "content/projects/statcheck/statcheck.html#links",
    "href": "content/projects/statcheck/statcheck.html#links",
    "title": "statcheck",
    "section": "Links",
    "text": "Links\n\nThe web app\nThe R package on CRAN\nThe GitHub page of statcheck\nThe GitHub page of the statcheck Word add-in."
  },
  {
    "objectID": "content/projects/tidystats/tidystats.html",
    "href": "content/projects/tidystats/tidystats.html",
    "title": "tidystats",
    "section": "",
    "text": "tidystats is a project centered around creating software to improve how statistics are reported and shared in the field of (social) psychology."
  },
  {
    "objectID": "content/projects/tidystats/tidystats.html#why-is-this-important",
    "href": "content/projects/tidystats/tidystats.html#why-is-this-important",
    "title": "tidystats",
    "section": "Why is this important?",
    "text": "Why is this important?\nWith this project, I hope to address two problems in statistics reporting: Incorrect and incomplete statistics reporting.\nStatistics are often reported incorrectly (Nuijten et al., 2016). I think this is because researchers do not have the necessary software tools to reliably take the output of statistics from their data analysis software and enter it into their text editor. Instead, researchers are likely to copy statistics from the output by hand or by copy-pasting the output. Both techniques are error-prone, resulting in many papers containing statistical typos. This is a problem because statistical output is used in meta-analyses to aggregate the statistical evidence for theories, which in turn may affect policy. In some cases, the errors may even be so large that it affects the conclusion drawn from the statistical test.\nThere is also a more fundamental issue. Researchers usually only report the statistics in their manuscript and nowhere else. As a result, researchers face trade-offs between reporting all statistics, writing a legible text, and journal guidelines. Reporting all statistics makes results sections difficult (and boring) to read and it also takes up valuable space. Consequently, researchers are likely to only report the statistics that they deem to be relevant, rather than reporting all the statistics. While this is fine for someone who wants to simply read the paper and get the main takeaway, this is not desirable from a cumulative science perspective. All statistics should be easily available so they can be build on in future research."
  },
  {
    "objectID": "content/projects/tidystats/tidystats.html#what-am-i-working-on",
    "href": "content/projects/tidystats/tidystats.html#what-am-i-working-on",
    "title": "tidystats",
    "section": "What am I working on?",
    "text": "What am I working on?\nI have designed an R package called tidystats that enables researchers to export the statistics from their analyses into a single file. It works by adding your analyses to a list (in R) and then exporting this list to a JSON file. This file will contain all the statistics from the analyses, in an organized format, ready to be used in other software.\nBy storing the output of statistical tests into a separate file, rather than only in one’s manuscript, the researcher no longer needs to worry about which analyses to report in the space-limited manuscript. They can simply share the file together with the manuscript, on OSF or as supplemental material.\nAn additional benefit is that because JSON files are easy to read for computers, it is (relatively) easy to write software that does cool things with these files.\nAn example of software that can read the JSON file is the tidystats Microsoft Word add-in. This add-in can be installed via the Add-in Store from inside Word. With this add-in, researchers can upload the JSON file to reveal a user-friendly list of their analyses. Clicking on an analysis reveals the associated statistics and clicking on a statistic inserts it into the document. This add-in also comes with several time-saving features, such as inserting multiple statistics at once (immediately in APA style) and automatic updating of statistics.\nRecently, I’ve also obtained a grant to work on tidystats. Thanks to this grant, the functionality of tidystats will be expanded, both in terms of adding support for more analyses and by expanding to other platforms, such as Python and Google Docs.\nBesides working on the software itself, I also spent some time on making it accessible. I have given talks introducing tidystats and I’ve created a website to help people become familiar with tidystats."
  },
  {
    "objectID": "content/projects/tidystats/tidystats.html#links",
    "href": "content/projects/tidystats/tidystats.html#links",
    "title": "tidystats",
    "section": "Links",
    "text": "Links\n\nThe tidystats website\nR package on CRAN\nR package GitHub repository\nThe tidystats Word add-in in AppSource (the Office add-in store)\nWord add-in GitHub repository\nA blog post describing an example of using tidystats"
  },
  {
    "objectID": "content/projects/cognitive-dissonance/cognitive-dissonance.html",
    "href": "content/projects/cognitive-dissonance/cognitive-dissonance.html",
    "title": "Cognitive dissonance",
    "section": "",
    "text": "Cognitive dissonance refers to a state of aversive arousal that is experienced when people realize they possess mutually inconsistent cognitions. This state is the foundation of cognitive dissonance theory (CDT)—a theory developed by Leon Festinger in 1957. Several of my projects are aimed at assessing the evidence for this theory and at applying this theory to other issues (although now that I’ve left academia, these projects have been deprioritized)."
  },
  {
    "objectID": "content/projects/cognitive-dissonance/cognitive-dissonance.html#why-is-this-important",
    "href": "content/projects/cognitive-dissonance/cognitive-dissonance.html#why-is-this-important",
    "title": "Cognitive dissonance",
    "section": "Why is this important?",
    "text": "Why is this important?\nThe theory of cognitive dissonance can explain many different phenomena that we should understand so that we may intervene and improve the lives of others. For example, cognitive dissonance theory has been used to explain religious beliefs, unhealthy behaviors, and people’s attitude towards animals.\nBefore the theory can be applied, however, it needs to be verified. We need to have sufficient evidence to believe in the theory. The social psychological evidence we have for the theory is, however, quite weak. The research stems from old research, mostly conducted in the 50s, 60s, and 70s. While this would not necessarily be a problem, it is a problem in the case of social psychology. The original studies were conducted with extremely low sample sizes and without pre-registration, or other tools that limit p-hacking. This means that many past findings may be false positives, which is supported by recent findings that show many findings in psychology do not replicate."
  },
  {
    "objectID": "content/projects/cognitive-dissonance/cognitive-dissonance.html#what-am-i-working-on",
    "href": "content/projects/cognitive-dissonance/cognitive-dissonance.html#what-am-i-working-on",
    "title": "Cognitive dissonance",
    "section": "What am I working on?",
    "text": "What am I working on?\nI am one of the lead investigators of a large-scaled replication project. In this project, we will try and replicate a seminal finding in the cognitive dissonance literature. Specifically, our aim is to replicate the classic finding that people who write a counterattitudinal essay (e.g., students arguing in favor of a tuition increase) become more in favor of the position they argued for. We have submitted this project as a registered report to Advanced in Methods and Practices in Psychological Science (AMPPS). There it has received an in-principle acceptance. Data collection is currently underway.\nI also hope to start up a meta-analysis project to produce live reviews of studies from the cognitive dissonance literature."
  },
  {
    "objectID": "content/projects/cognitive-dissonance/cognitive-dissonance.html#links",
    "href": "content/projects/cognitive-dissonance/cognitive-dissonance.html#links",
    "title": "Cognitive dissonance",
    "section": "Links",
    "text": "Links\n\nThe landing page of our large-scaled replication project\nThe stage-1 accepted manuscript"
  },
  {
    "objectID": "content/projects.html",
    "href": "content/projects.html",
    "title": "Projects",
    "section": "",
    "text": "Farm animals and wild animals suffer in horrible ways in great numbers. At Rethink Priorities, I contribute to various projects aimed at addressing this important problem.\n\n\n\n\n\n\n\n\n\n\n\nIn this project I aim to assess the evidence for cognitive dissonance theory using a large-scaled replication study of a seminal cognitive dissonance study.\n\n\n\n\n\n\n\n\n\n\n\nTogether with Michèle Nuijten I am working on improving statcheck. statcheck is a software tool to help researchers make fewer statistics-related typos.\n\n\n\n\n\n\n\n\n\n\n\ntidystats refers to a collection of software solutions to improve how statistics are reported and shared in the field of (social) psychology.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/about.html",
    "href": "content/about.html",
    "title": "About",
    "section": "",
    "text": "Before joining Rethink Priorities, I was an assistant professor in the Department of Social Psychology at Tilburg University.\nOn this website you can find information about some of the projects I’m involved in. Some notable projects I’m working on are tidystats and a large-scaled replication study of cognitive dissonance. Besides writing about these projects, I also blog posts about various topics, including tutorials or opinion pieces.\nOne of my main research interests concern animal welfare. I think animal welfare, and their lack thereof, is one of the most pressing issues in the world at this moment and as a fruitful area of research where influential theories in social psychology (such as cognitive dissonance) can be applied and tested.\nI’m also interested in the methodology of psychological research and ways to improve how we conduct science. A notable project I’m working on is tidystats. This is a software solution to help researchers more easily and more reproducibly report statistics in scientific manuscripts. It’s main goal is to get researchers to report more statistics with fewer errors. I’m pretty proud of this project, so please check it out on the tidystats project or the tidystats website.\nI also have teaching experience thanks to my time as an assistant professor. I’m quite experienced in teaching undergraduate courses, in both small and large groups of students. Besides course work I have also provided many R workshops (although I have less time for that now).\nThis website is created using Quarto."
  },
  {
    "objectID": "content/cv/cv.html#employment",
    "href": "content/cv/cv.html#employment",
    "title": "Willem Sleegers",
    "section": "Employment",
    "text": "Employment\n\n\n\n\n\n\n\n\n\n2021-current\nSenior Behavioral Scientist at Rethink Priorities\n\n\n2018-2021\nTenure track Assistant Professor in social psychology at Tilburg University\n\n\n2016-2018\nFixed term Assistant Professor in social psychology at Tilburg University\n\n\n2012-2016\nGraduate student on the topic of physiological arousal in meaning maintenance at Tilburg University\n\n\n2011-2012\nStudent assistant during my Research Master: Behavioral Science at Nijmegen University\n\n\n2012-2013\nProgrammer of experimental psychology tasks for FrieslandCampina\n\n\n2007-2010\nMedia analyst for Report International"
  },
  {
    "objectID": "content/cv/cv.html#education",
    "href": "content/cv/cv.html#education",
    "title": "Willem Sleegers",
    "section": "Education",
    "text": "Education\n\n\n\n\n\n\n\n\n\n2012-2016\nGraduate student at Tilburg University supervised by prof. dr. Ilja van Beest and dr. Travis Proulx\n\n\n2012-2016\nStudent member of the Kurt Lewin Institute (KLI)\n\n\n2010-2012\nResearch Master Behavioural Science at Nijmegen University\n\n\n2010-2012\nExpert track in data-analysis\n\n\n2007-2010\nPsychology BSc. at Nijmegen University\n\n\n2007-2010\nHonours Program of Psychology at Nijmegen University"
  },
  {
    "objectID": "content/cv/cv.html#publications",
    "href": "content/cv/cv.html#publications",
    "title": "Willem Sleegers",
    "section": "Publications",
    "text": "Publications\n\nIn preparation\n\n\n\n\n\n\n\n\nvan Leeuwen, F., Jaeger, B., Sleegers, W. W. A., & Petersen, M. B. (in prep.) Pathogen avoidance and conformity: Salient infectious disease does not increase conformity.\n\n\nJaeger, B., Sleegers, W. W. A., Stern, J., Penke, L., & Jones, A. (in prep.) The accuracy and meta-accuracy of personality impressions from faces.\n\n\nSleegers, W. W. A. & Jaeger, B. (in prep.) The social cost of correcting others.\n\n\n\n\n\n\n\nPreprints\n\n\n\n\n\n\n\n\nJaeger, B., Sleegers, W. W. A. (2020) Racial discrimination in the sharing economy: Evidence from Airbnb markets across the world. https://psyarxiv.com/qusxf\n\n\nBreznau, N., et al. (2021) The Crowdsourced Replication Initiative: Investigating Immigration and Social Policy Preferences. Executive Report. https://osf.io/preprints/socarxiv/6j9qb/\n\n\nBreznau, N., et al. (2021) How many replicators does it take to achieve reliability? Investigating researcher variability in a crowdsourced replication. https://osf.io/preprints/socarxiv/j7qta/\n\n\n\n\n\n\n\nStage-1 accepted manuscripts\n\n\n\n\n\n\n\n\n\n2021\nSleegers, W. W. A., Vaidis, D. (shared first author) et al. (2021). A multi-lab replication of the induced compliance paradigm of cognitive dissonance. Advances in Methods and Practices in Psychological Science. https://osf.io/52wpj\n\n\n\n\n\n\n\nPeer-reviewed journals\n\n\n\n\n\n\n\n\n\n2021\nPronk, T. M., Bogaers, R. I., Verheijen, M. S., Sleegers, W. W. A. (in press). Pupil size predicts partner choices in online dating. Social Cognition.\n\n\n2021\nEvans, A. M., Kogler, C., & Sleegers, W. W. A. (in press). No effect of synchronicity in online social dilemma experiments: A registered report. Judgment and Decision Making.\n\n\n2021\nVan Osch, Y., & Sleegers, W. W. A. (2021). Replicating and reversing the group attractiveness effect: Relatively unattractive groups are perceived as less attractive than the average attractiveness of their members. Acta Psychologica, 217, 103331. https://.doi.org/10.1016/j.actpsy.2021.103331\n\n\n2021\nBrandt, M., Sleegers, W. W. A. (2021) Evaluating belief system networks as a theory of political belief system dynamics, 25(2), 159-185. https://doi.org/10.1177/1088868321993751\n\n\n2021\nJones, B. C., DeBruine, L. M., Flake, J. K., et al. (2021) To which world regions does the valence–dominance model of social perception apply? Nature Human Behavior, 5, 159–169. https://doi.org/10.1038/s41562-020-01007-2\n\n\n2020\nSleegers, W. W. A., Proulx, T., & van Beest, I. (2020) Pupillometry and hindsight bias: Physiological arousal predicts compensatory behavior. Social Psychological and Personality Science. https://doi.org/10.1177/1948550620966153\n\n\n2020\nEvans, A., Sleegers, W. W. A., & Mlakar, Ž. (2020). Individual differences in receptivity to scientific bullshit. Judgment and Decision Making, 15(3), 401-412.\n\n\n2020\nJaeger, B., Sleegers, W. W. A., & Evans, A. M. (2020). Automated classification of demographics from face images: A tutorial and validation. Social and Personality Psychology Compass, 14(3). https://doi.org/10.1111/spc3.12520\n\n\n2019\nSleegers, W. W. A., Proulx, T., & van Beest, I. (2019). Confirmation bias and misconceptions: Pupillometric evidence for a confirmation bias in misconceptions feedback. Biological Psychology, 145, 76–83. https://doi.org/10.1016/j.biopsycho.2019.03.018\n\n\n2019\nBender, M., van Osch, Y., Sleegers, W. W. A., & Ye, M. (2019). Social support benefits psychological adjustment of international students: Evidence from a meta-analysis. Journal of Cross-Cultural Psychology, 50(7), 827–847. https://doi.org/10.1177/0022022119861151\n\n\n2019\nVan ’t Veer, A. E., & Sleegers, W. W. A. (2019). Psychology data from an exploration of the effect of anticipatory stress on disgust vs. Non-disgust related moral judgments. Journal of Open Psychology Data, 7(1), 1. https://doi.org/10.5334/jopd.43\n\n\n2018\nJaeger, B., Sleegers, W. W. A., Evans, A. M., Stel, M., & van Beest, I. (2018). The effects of facial attractiveness and trustworthiness in online peer-to-peer markets. Journal of Economic Psychology. https://doi.org/https://doi.org/10.1016/j.joep.2018.11.004\n\n\n2017\nProulx, T., Sleegers, W. W. A., & Tritt, S. (2017). The expectancy bias: Expectancy-violating faces evoke earlier pupillary dilation than neutral or negative faces. Journal of Experimental Social Psychology, 70, 69-79. https://doi.org/10.1016/j.jesp.2016.12.003\n\n\n2017\nSleegers, W. W. A., Proulx, T., & van Beest, I. (2017). The social pain of Cyberball: Decreased pupillary reactivity to exclusion cues. Journal of Experimental Social Psychology, 69, 187–200. https://doi.org/10.1016/j.jesp.2016.08.004\n\n\n2015\nSleegers, W. W. A., Proulx, T., & van Beest, I. (2015). Extremism reduces conflict arousal and increases values affirmation in response to meaning violations. Biological Psychology, 108, 126–131. https://doi.org/10.1016/j.biopsycho.2015.03.012\n\n\n2015\nSleegers, W. W. A., & Proulx, T. (2015). The comfort of approach: Self-soothing effects of behavioral approach in response to meaning violations. Frontiers in Psychology, 5, 1–10. https://doi.org/10.3389/fpsyg.2014.01568\n\n\n\n\n\n\n\nBook chapters\n\n\n\n\n\n\n\n\n\n2019\nvan Beest, I., & Sleegers, W.W.A (2019). Physiostracism: A case for non-invasive measures of arousal in ostracism research. In S. C. Rudert, R. Greifeneder, & K. D. Williams (Eds.), Current directions in ostracism, social exclusion and rejectionresearch. Routledge. https://doi.org/10.4324/9781351255912\n\n\n\n\n\n\n\nDissertation\n\n\n\n\n\n\n\n\n\n2017\nSleegers, W. W. A. (2017). Meaning and pupillometry: The role of physiological arousal in meaning maintenance (Doctoral dissertation). Retrieved from https://pure.uvt.nl/portal/en/publications/meaning-and-pupillometry(20680e63-e785-43d0-a3ae-e97b26de5f05).html\n\n\n\n\n\n\n\nSoftware\n\n\n\n\n\n\n\n\n\n2020\nSleegers, W. W. A. (2020). tidystats: Save output of statistical tests (Version 0.5) [Computer software]. https://doi.org/10.5281/zenodo.4041859\n\n\n2020\nSleegers, W. W. A. (2020). tidystats (Version 1) [Computer software]. https://doi.org/10.5281/zenodo.4434634\n\n\n\n\n\n\n\nWebsites\n\n\n\n\n\n\n\n\nMy personal website where I blog about (some of) my research.https://www.willemsleegers.com\n\n\nThe tidystats website, a support website for my tidystats software.https://www.tidystats.io"
  },
  {
    "objectID": "content/cv/cv.html#presentations",
    "href": "content/cv/cv.html#presentations",
    "title": "Willem Sleegers",
    "section": "Presentations",
    "text": "Presentations\n\nInvited talks\n\n\n\n\n\n\n\n\n\n2021\nSleegers, W. W. A. (2021, March). tidystats. Talk for a research group at the Ministry of Defence.\n\n\n2021\nSleegers, W. W. A. (2021, February). tidystats. Talk for the BSI at Nijmegen University.\n\n\n2021\nSleegers, W. W. A. (2021, February). Cognitive dissonance RRR. Lab meeting at Cardiff University.\n\n\n2018\nSleegers, W. W. A. (2018, December). Pupillometry and psychology. Colloquium presentation for the Laboratoire de Psychologie Sociale department at Paris Descartes University.\n\n\n2018\nSleegers, W. W. A. (2018, October) tidystats. Colloquium presentation for the Methodology and Statistics department at Leiden University.\n\n\n2018\nSleegers, W. W. A. (2018, March) tidystats. Colloquium presentation for the MTO department at Tilburg University.\n\n\n2017\nSleegers, W. W. A. (2017, December). Meaning and pupillometry: The role of physiological arousal in meaning maintenance. Presentation at the ASPO conference as part of receiving the best ASPO dissertation award.\n\n\n2017\nSleegers, W. W. A. (2017, March). Pupillometry and psychological processes. Colloquium presentation at Cardiff University.\n\n\n2015\nSleegers, W. W. A., Proulx, T. & Van Beest, I. (2015, October). Capturing the physiological response to meaning violations: An eye tracker approach. Colloquium presentation at Tilburg University.\n\n\n\n\n\n\n\nConference presentations\n\n\n\n\n\n\n\n\n\n2019\nSleegers, W. W. A. (2019, July) tidystats. Lightning talk at the SIPS conference, Rotterdam, the Netherlands.\n\n\n2019\nSleegers, W. W. A. & Jaeger, B. (2019, December) The Social Cost of Correcting Others. Talk at the ASPO conference, Wageningen, the Netherlands.\n\n\n2018\nSleegers, W. W. A. (2018, June) tidystats. Lightning talk at the SIPS conference, Grand Rapids, MI.\n\n\n2017\nSleegers, W. W. A. (2017, August). oTree for social scientists. Presentation at the TIBER conference, Tilburg, the Netherlands.\n\n\n2016\nSleegers, W. W. A., Proulx, T. & Van Beest (2016, December). Evidence of aversive arousal motivating compensatory behavior. Presentation at ASPO conference, Leiden, the Netherlands.\n\n\n2014\nProulx, T. & Sleegers, W. W. A. (2014, May). Meaning Maintenance Model: Towards a unified account of threat-compensation behaviors. Presentation at KLI conference, Zeist, the Netherlands.\n\n\n2014\nSleegers, W. W. A., Proulx, T., & Van Beest (2014, December). Cyberball and eye tracking: Support for the numbing hypothesis of social exclusion. Presentation at ASPO 2014, Groningen, the Netherlands.\n\n\n2014\nSleegers, W. W. A., Proulx, T., & Van Beest (2014, July). Ostracism and eye tracking. Presentation at EASP preconference on threat regulation, Amsterdam, the Netherlands.\n\n\n\n\n\n\n\nSmall meetings\n\n\n\n\n\n\n\n\n\n2019\nSleegers, W. W. A. (2019, November) Addressing Incorrect and Incomplete Statistics Reporting (with tidystats). Talk at the meta-research day at Tilburg University, the Netherlands.\n\n\n\n\n\n\n\nPoster presentations\n\n\n\n\n\n\n\n\n\n2017\nSleegers, W. W. A. (2017, July). Pupillometry and psychology: Pupillometry as an experimental tool for psychologists. Poster session presented at the Ostracism, Social Exclusion, and Rejection conference, Vitznau, Switzerland.\n\n\n2016\nSleegers, W. W. A., Proulx, T., & Van Beest (2016, January). Ostracism and eye tracking: Decreased pupillary reactivity to exclusion cues. Poster session presented at the SPSP conference, San Diego.\n\n\n2015\nSleegers, W. W. A., Proulx, T., & Van Beest (2015, December). Meaning and misconceptions: The effect of error feedback and commitment towards misconceptions on pupil size. Poster session presented at ASPO conference, Amsterdam.\n\n\n2015\nSleegers, W. W. A., Proulx, T. & Van Beest (2015, March). Cyberball and eye tracking: Support for the numbing hypothesis of social exclusion. Poster session presented at ICPS conference, Amsterdam, the Netherlands.\n\n\n2014\nSleegers, W. W. A., Proulx, T, & Van Beest, I. (2014, May). Extremism and the response to meaning threats: Extremism reduces pupillary response to threat and increases affirmation of values. Poster session presented at the KLI conference, Zeist, the Netherlands.\n\n\n\n\n\n\n\nValorization presentations\n\n\n\n\n\n\n\n\n\n2017\nSleegers, W. W. A., & Wagemans, F. M. A. (2017, November). The psychology behind eye tracking. Presentation organized by the Academic Forum of Tilburg University.\n\n\n2017\nWagemans, F. M. A., & Sleegers, W. W. A. (2017, June). Waar walg jij van? Presentation at Mundial festival on attentional processes and disgust sensitivity using eye tracking."
  },
  {
    "objectID": "content/cv/cv.html#journals",
    "href": "content/cv/cv.html#journals",
    "title": "Willem Sleegers",
    "section": "Journals",
    "text": "Journals\n\n\n\nI reviewed for Behavioural Processes, Biological Psychology, British Journal of Psychology, British Journal of Social Psychology, Collabra, European Journal of Social Psychology, Group Processes & Intergroup Relations, International Journal of Psychology, International Review of Social Psychology, Journal of Consumer Behaviour, Journal of Experimental Social Psychology, Journal of Social and Personal Relationships, Personality and Social Psychology Bulletin, PLOS ONE, Self and Identity, Social Cognition, Social Influence, Social Psychology, Current Psychology, Journal of Cognitive Psychology."
  },
  {
    "objectID": "content/cv/cv.html#teaching",
    "href": "content/cv/cv.html#teaching",
    "title": "Willem Sleegers",
    "section": "Teaching",
    "text": "Teaching\n\nCourses\n\n\n\n\n\n\n\n\n\n2017-2021\nSocial Psychology\n\n\n2016-2021\nAttitudes and Advertising\n\n\n2019-2021\nUnderstanding Data with R\n\n\n2015/2017/2019\nResearch Master: Experimental Research and Meta-Analysis\n\n\n2016-2021\nCourse in R software\n\n\n2019-2021\nUnderstanding Data with R\n\n\n\n\n\n\n\nSeminars\n\n\n\n\n\n\n\n\n\n2012-2017\nSocial Psychology\n\n\n2015-2016\nIntroduction and History of Psychology\n\n\n2014-2015\nCultural Psychology\n\n\n2013-2015\nAcademic Skills\n\n\n2012-2013\nGroup Skills\n\n\n\n\n\n\n\nIndividual lectures\n\n\n\n\n\n\n\n\n\n2016\nSocial Psychology\n\n\n2014\nIntroduction and History of Psychology on intrapersonal conflict\n\n\n2013\nIntroduction to Social Psychology for prospective students\n\n\n\n\n\n\n\nSupervision\n\n\n\n\n\n\n\n\n\n2021\nResearch Master in Psychology theses\n\n\n2016-2021\nMaster in Psychology theses\n\n\n2013-2021\nBachelor in Psychology theses\n\n\n2012-2018\nResearch Skills in Psychology\n\n\n\n\n\n\n\nCoordination\n\n\n\n\n\n\n\n\n\n2014-2021\nSocial Psychology\n\n\n2016-2021\nAttitudes and Advertising\n\n\n\n\n\n\n\nOther\n\n\n\n\n\n\n\n\n\n2013-2021\nAn introduction to R; part of the Kurt Lewin Institute course program"
  },
  {
    "objectID": "content/cv/cv.html#technical-skills",
    "href": "content/cv/cv.html#technical-skills",
    "title": "Willem Sleegers",
    "section": "Technical skills",
    "text": "Technical skills\n\nStatistics\n\n\n\n\n\nR: A free software environment for statistical computing and graphics\n\n\nSPSS: A proprietary data analysis program"
  },
  {
    "objectID": "content/cv/cv.html#programming",
    "href": "content/cv/cv.html#programming",
    "title": "Willem Sleegers",
    "section": "Programming",
    "text": "Programming\n\n\n\n\n\nPython: A cross-platform procedural programming language\n\n\nHTML: Markup language for creating web pages and web applications\n\n\nCSS: Markup language for styling web pages and web applications\n\n\nJavaScript: A programming language for creating web applications\n\n\nDjango: A high-level Python Web framework\n\n\nHugo: A static HTML and CSS website generator\n\n\n\n\n\n\nExperimental design\n\n\n\n\n\n\n\n\nMillisecond’s Inquisit: Stimulus delivery and experimental design software\n\n\noTree: Framework based on Python and Django to create standard and interactive online psychological experiments\n\n\nTobii Studio and Tobii Studio Extensions for E-prime: software to run eye tracker experiments using Tobii eye trackers\n\n\nPsychology Software Tool’s E-Prime: Stimulus delivery and experimental design software\n\n\nAdobe’s Authorware: Stimulus delivery and experimental design software. This has been discontinued, please do not make me use it\n\n\nNeurobehavioural Systems’ Presentation®: A stimulus delivery and experimental control program for neuroscience"
  },
  {
    "objectID": "content/blog.html",
    "href": "content/blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\ntutorial\n\n\nBayesian statistics\n\n\nregression\n\n\n\n\nThe fourth of a series of tutorial posts on Bayesian analyses. In this post I focus on using brms to model the difference between two groups.\n\n\n\n\n\n\nApr 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\ntutorial\n\n\nBayesian statistics\n\n\nregression\n\n\n\n\nThe third of a series of tutorial posts on Bayesian analyses. In this post I focus on using brms to model a correlation.\n\n\n\n\n\n\nFeb 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\ntutorial\n\n\nBayesian statistics\n\n\nregression\n\n\n\n\nThe second of a series of tutorial posts on Bayesian analyses. In this post I focus on using brms to run a regression with a single predictor.\n\n\n\n\n\n\nFeb 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\ntutorial\n\n\nBayesian statistics\n\n\nregression\n\n\n\n\nThe first of a series of tutorial posts on Bayesian analyses. In this post I focus on using brms to run an intercept-only regression model.\n\n\n\n\n\n\nFeb 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanimal welfare\n\n\ndata cleaning\n\n\nAPIs\n\n\npolitics\n\n\n\n\n\n\n\n\n\n\n\nSep 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanimal welfare\n\n\ndata cleaning\n\n\ndata visualization\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npower analysis\n\n\nsimulation\n\n\nstatistics\n\n\n\n\n\n\n\n\n\n\n\nNov 9, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\npower analysis\n\n\nsimulation\n\n\n\n\nSimulation-based power analyses make it easy to understand what power is: Power is simply counting how often you find the results you expect to find. Running simulation-based power analyses might be new for some, so in this blog post I present code to simulate data for a range of different scenarios.\n\n\n\n\n\n\nOct 23, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwriting\n\n\nstatistics\n\n\npower analysis\n\n\n\n\nMethod sections in academic (psychology) papers usually consist of the following sections: Participants, Design, Procedure, and Materials. They also tend to be presented in this order. But is this, generally speaking, the right order? I don’t think so.\n\n\n\n\n\n\nJul 8, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntidystats\n\n\nstatistics\n\n\ntutorial\n\n\n\n\nI illustrate how to use my tidystats software to analyze and report the results of a replication study that was part of the Many Labs 1 project.\n\n\n\n\n\n\nApr 25, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\n\n\nIn a recent tweet I asked the question why we use \\(n - 1\\) to calculate the variance of a sample. Many people contributed an answer, but many of them were of the type I feared. Most consisted of some statistical jargon that confuses me more, rather than less. Other responses were very useful, though, so I recommend checking out the replies to the tweet. In this post, I will try to describe my favorite way of looking at the issue.\n\n\n\n\n\n\nAug 5, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\npower analysis\n\n\n\n\nA curious thing happened in the field of social psychology: Social psychologists finally realized that statistical power is important. Unfortunately, they then skipped the step of figuring out how to do them correctly. Here I list some papers on power analyses that I hope help in improving the way we do them.\n\n\n\n\n\n\nAug 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistics\n\n\ntutorial\n\n\nregression\n\n\n\n\nThis is Part 1 of a series of blog posts on how to understand regression. The goal is to develop an intuitive understanding of the different components of regression. In this first post, we figure out where the estimate of an intercept-only regression model comes from.\n\n\n\n\n\n\nAug 1, 2020\n\n\n\n\n\n\nNo matching items"
  }
]